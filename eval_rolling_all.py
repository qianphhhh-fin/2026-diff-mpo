"""
è„šæœ¬åç§°: eval_rolling_all.py
åŠŸèƒ½æè¿°: 
    "Grand Challenge" æ»šåŠ¨å›æµ‹ä¸»å¼•æ“ã€‚
    åœ¨çœŸå®çš„æ—¶é—´è½´ä¸Šæ¨¡æ‹Ÿäº¤æ˜“ï¼Œå¯¹æ¯” Diff-MPO ä¸å…¶ä»–åŸºå‡†ç­–ç•¥çš„ç»©æ•ˆã€‚

ä¸»è¦æµç¨‹:
    1. åˆå§‹åŒ–æ‰€æœ‰ç­–ç•¥ (Diff-MPO, Mean-Var, 1/N ç­‰)ã€‚
    2. æŒ‰å¹´ä»½è¿›è¡Œæ»šåŠ¨å›æµ‹ (Walk-Forward Validation):
       - æ¯å¹´åˆï¼Œä½¿ç”¨è¿‡å»çš„æ•°æ®å¯¹ DeepMPO è¿›è¡Œå¾®è°ƒ (Retraining)ã€‚
       - æ¯æ—¥è¿›è¡Œæ¨ç†ï¼Œè·å–ç›®æ ‡æƒé‡ã€‚
       - æ¨¡æ‹Ÿäº¤æ˜“ï¼Œè®¡ç®—æ¯æ—¥æ”¶ç›Šå’Œæ¢æ‰‹ç‡ã€‚
    3. ç»©æ•ˆè¯„ä¼°: è®¡ç®— Sharpe, Sortino, Calmar, MaxDD, Turnover ç­‰æŒ‡æ ‡ã€‚
    4. å¯è§†åŒ–: ç»˜åˆ¶å‡€å€¼æ›²çº¿å¹¶ä¿å­˜ç»“æœã€‚

è¾“å…¥:
    - 'mpo_experiment_data.csv' (åŸå§‹æ•°æ®)ã€‚
    - ç­–ç•¥å®šä¹‰ (strategy.py)ã€‚

è¾“å‡º:
    - ç»©æ•ˆæŒ‡æ ‡è¡¨æ ¼ (æ§åˆ¶å°æ‰“å° & CSV ä¿å­˜)ã€‚
    - å‡€å€¼æ›²çº¿å›¾ 'results/grand_challenge_wealth_curves.png'ã€‚
    - æ¯æ—¥æ”¶ç›Šå’Œæ¢æ‰‹ç‡åºåˆ— CSVã€‚

ä¸å…¶ä»–è„šæœ¬çš„å…³ç³»:
    - é¡¹ç›®çš„æœ€ç»ˆå‡ºå£ï¼Œæ•´åˆäº† data_loader, strategy, model, mpo_solver ç­‰æ‰€æœ‰æ¨¡å—ã€‚
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import torch
import random
import os
from tqdm import tqdm
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader

# å¼•å…¥è‡ªå®šä¹‰æ¨¡å—
from config import cfg
from data_loader import MPODataset
from strategy import (
    RuleBasedStrategy, 
    OptimizationStrategy, 
    DeepMPOStrategy,
    DirectGradientStrategy, # <--- æ–°å¢
    HRPStrategy,  # <--- æ–°å¢
    DeepE2EStrategy
)

# è®¾ç½®ç»˜å›¾é£æ ¼
plt.style.use('seaborn-v0_8')

def seed_everything(seed=42):
    """å›ºå®šæ‰€æœ‰éšæœºç§å­ä»¥ä¿è¯ç»“æœå¯å¤ç°"""
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    # ä¿è¯ CuDNN çš„ç¡®å®šæ€§ (ä¼šç‰ºç‰²ä¸€ç‚¹é€Ÿåº¦)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

def calculate_metrics(returns_series, turnover_series, name):
    """è®¡ç®—å›æµ‹æŒ‡æ ‡"""
    # å¹´åŒ–æ”¶ç›Š
    ann_ret = returns_series.mean() * 252
    
    # å¹´åŒ–æ³¢åŠ¨
    ann_vol = returns_series.std() * np.sqrt(252)
    
    # Sharpe (æ— é£é™©åˆ©ç‡å‡å®šä¸º 2%)
    rf = 0.02
    sharpe = (ann_ret - rf) / (ann_vol + 1e-6)
    
    # Sortino (åªè€ƒè™‘ä¸‹è¡Œæ³¢åŠ¨)
    downside = returns_series.copy()
    downside[downside > 0] = 0
    downside_std = downside.std() * np.sqrt(252)
    sortino = (ann_ret - rf) / (downside_std + 1e-6)
    
    # Max Drawdown
    # wealth æ˜¯ numpy array
    wealth = (1 + returns_series).cumprod()
    
    # --- ä¿®æ”¹ç‚¹å¼€å§‹ ---
    # numpy æ²¡æœ‰ .cummax()ï¼Œè¦ç”¨ np.maximum.accumulate()
    cummax = np.maximum.accumulate(wealth) 
    # --- ä¿®æ”¹ç‚¹ç»“æŸ ---
    
    drawdown = (wealth - cummax) / cummax
    max_dd = drawdown.min()
    
    # Calmar Ratio
    calmar = ann_ret / (abs(max_dd) + 1e-6)
    
    # Turnover
    avg_turnover = turnover_series.mean()
    
    return {
        "Strategy": name,
        "Return": f"{ann_ret:.2%}",
        "Sharpe": f"{sharpe:.2f}",
        "Sortino": f"{sortino:.2f}",
        "Calmar": f"{calmar:.2f}",
        "MaxDD": f"{max_dd:.2%}",
        "Turnover": f"{avg_turnover:.2%}"
    }

def run_comprehensive_backtest():
    # 1. è®¾ç½®éšæœºç§å­
    seed_everything(cfg.SEED)
    print(f"ğŸ”’ Random Seed set to {cfg.SEED}")

    print("âš”ï¸ [Grand Challenge] æ»šåŠ¨å›æµ‹ç«æŠ€åœºå¯åŠ¨ ...")
    print(f"   Device: {cfg.DEVICE}")
    print(f"   Transaction Cost: {cfg.COST_COEFF * 10000:.0f} bps")
    
    # ==========================================
    # 1. åˆå§‹åŒ–ç­–ç•¥æ± 
    # ==========================================
    # è¿™é‡Œæˆ‘ä»¬å®ä¾‹åŒ–æ‰€æœ‰æƒ³è¦å¯¹æ¯”çš„ç­–ç•¥
    strategies = [
        # --- åŸºå‡† (Benchmarks) ---
        RuleBasedStrategy('1/N Benchmark'),
        RuleBasedStrategy('Risk Parity (1Y)'),
        RuleBasedStrategy('Factor Momentum (Top3)'),
        
        # --- ä¼ ç»Ÿä¼˜åŒ– (Classic Optimization) ---
        # æ³¨æ„ï¼šMean-CVaR è®¡ç®—è¾ƒæ…¢ï¼Œå¦‚æœä½ æƒ³å¿«é€Ÿè·‘é€šå¯ä»¥å…ˆæ³¨é‡Šæ‰
        OptimizationStrategy('Mean-Variance', lookback=60),
        OptimizationStrategy('Global Min Var', lookback=60),
        OptimizationStrategy('Mean-CVaR', lookback=60), 
        HRPStrategy('Hierarchical Risk Parity', lookback=252),
           
        # --- æ·±åº¦å­¦ä¹  (Ours) ---
        DeepMPOStrategy('Diff-MPO (Factor Model)'),
        # æ–°å¢ï¼šç›´æ¥åœ¨å†å²ä¸Šä¼˜åŒ– Loss çš„ç­–ç•¥
        DirectGradientStrategy('Direct Loss Opt (History)', lookback=60),
        DeepE2EStrategy('Deep E2E (Policy Net)'), # <--- ä½ çš„æ–°å¯¹æ‰‹
    ]
    
    # åˆå§‹åŒ–è®°å½•å™¨
    # results[strat_name] = [daily_net_returns]
    results = {s.name: [] for s in strategies}
    turnovers = {s.name: [] for s in strategies}
    
    # ç»´æŠ¤å½“å‰çš„æŒä»“æƒé‡ (ç”¨äºè®¡ç®—æ¢æ‰‹ç‡å’Œä½œä¸º w_prev)
    # åˆå§‹å…¨éƒ¨ä¸º 1/N
    current_weights = {
        s.name: np.ones(cfg.NUM_ASSETS) / cfg.NUM_ASSETS 
        for s in strategies
    }
    
    # ==========================================
    # 2. æ•°æ®å‡†å¤‡
    # ==========================================
    df_raw = pd.read_csv(cfg.DATA_PATH, index_col=0, parse_dates=True)
    all_features = df_raw.values 
    all_returns = df_raw[cfg.ASSETS].values
    dates = df_raw.index
    
    # è®¾ç½®å›æµ‹åŒºé—´
    TEST_START_YEAR = 2018
    TEST_END_YEAR = dates[-1].year
    
    print(f"   å›æµ‹åŒºé—´: {TEST_START_YEAR} -> {TEST_END_YEAR}")
    
    # ==========================================
    # 3. å¹´åº¦æ»šåŠ¨å¾ªç¯ (Walk-Forward Loop)
    # ==========================================
    for year in range(TEST_START_YEAR, TEST_END_YEAR + 1):
        print(f"\nğŸ“… å¤„ç†å¹´ä»½: {year} ...")
        
        # --- A. æ—¶é—´åˆ‡åˆ† (Expanding Window) ---
        train_end_dt = pd.Timestamp(f"{year}-01-01")
        test_end_dt = pd.Timestamp(f"{year+1}-01-01")
        
        train_mask = dates < train_end_dt
        test_mask = (dates >= train_end_dt) & (dates < test_end_dt)
        
        # ç¡®ä¿æ•°æ®è¶³å¤Ÿ
        if sum(test_mask) < cfg.LOOKBACK_WINDOW:
            print(f"   âš ï¸ {year} å¹´æ•°æ®ä¸è¶³ï¼Œè·³è¿‡ã€‚")
            continue
            
        # --- B. è®­ç»ƒé›†å‡†å¤‡ä¸æ ‡å‡†åŒ– (é˜²æ³„éœ²æ ¸å¿ƒ) ---
        scaler = StandardScaler()
        # Fit ä»…åœ¨è®­ç»ƒé›†ä¸Šè¿›è¡Œï¼
        X_train = scaler.fit_transform(all_features[train_mask])
        Y_train = all_returns[train_mask]
        
        # --- C. ç­–ç•¥é‡è®­ (Retraining Hook) ---
        # å¯¹äº DeepMPOï¼Œè¿™ä¼šè§¦å‘ Fine-tuning
        # å¯¹äºä¼ ç»Ÿç­–ç•¥ï¼Œé€šå¸¸åªæ˜¯ Pass
        
        # é¢„å…ˆæ„å»º DataLoader ä¾›æ·±åº¦æ¨¡å‹ä½¿ç”¨
        train_ds = MPODataset(X_train, Y_train, cfg.LOOKBACK_WINDOW, cfg.PREDICT_HORIZON)
        train_loader = DataLoader(train_ds, batch_size=cfg.BATCH_SIZE, shuffle=True, drop_last=True)
        
        for strat in strategies:
            # åªæœ‰ DeepMPOStrategy å®ç°äº†å…·ä½“çš„ on_train_period
            # æˆ‘ä»¬ä¸éœ€è¦åœ¨è¿™é‡Œåˆ¤æ–­ç±»å‹ï¼Œå¤šæ€æ€§ä¼šå¤„ç†å®ƒ
            if isinstance(strat, DeepMPOStrategy):
                print(f"   ğŸ”„ Retraining {strat.name}...")
            strat.on_train_period(train_loader)
            
        # --- D. é€æ—¥æ¨ç† (Daily Rolling Inference) ---
        # æ‰¾åˆ°æµ‹è¯•é›†åœ¨å…¨é‡æ•°æ®ä¸­çš„èµ·å§‹ä½ç½®
        test_start_idx = np.where(test_mask)[0][0]
        # å½“å¹´æ‰€æœ‰çš„äº¤æ˜“æ—¥
        test_indices = np.where(test_mask)[0]
        
        # ä½¿ç”¨ tqdm æ˜¾ç¤ºæ¯æ—¥è¿›åº¦
        pbar = tqdm(test_indices, desc=f"   Trading {year}", leave=False)
        
        for t_abs in pbar:
            # t_abs æ˜¯ç»å¯¹ç´¢å¼• (Absolute Index)
            # ç›®æ ‡ï¼šå†³å®š t_abs è¿™ä¸€å¤©çš„æŒä»“ï¼Œäº«å— t_abs å½“å¤©çš„æ”¶ç›Š Y[t_abs]
            # çº¦æŸï¼šåªèƒ½çœ‹åˆ° t_abs - 1 åŠä»¥å‰çš„æ•°æ®
            
            # 1. å‡†å¤‡å†å²è¾“å…¥çª—å£
            # åŸå§‹ç‰¹å¾çª—å£ [t - Lookback : t] (ä¸åŒ…å« t)
            # æ¯”å¦‚ t=100, lookback=60 -> å– [40:100], å³ indices 40...99
            x_window_raw = all_features[t_abs - cfg.LOOKBACK_WINDOW : t_abs]
            
            # å†å²æ”¶ç›Šçª—å£ (ç”¨äºä¼ ç»Ÿä¼˜åŒ–å™¨è®¡ç®— Covariance)
            # DataFrame åˆ‡ç‰‡æ˜¯åŒ…å«ç»“å°¾çš„ï¼Œæ‰€ä»¥ç”¨ iloc éœ€è¦å°å¿ƒ
            # iloc[start : end] ä¸åŒ…å« endã€‚
            # æˆ‘ä»¬éœ€è¦ 0 åˆ° t-1 çš„æ•°æ®ã€‚
            # ä¸ºäº†æ–¹ä¾¿ OptimizationStrategyï¼Œæˆ‘ä»¬ä¼ å…¥ DataFrame
            history_df_slice = df_raw[cfg.ASSETS].iloc[:t_abs] 
            
            # å®‰å…¨æ£€æŸ¥
            if len(x_window_raw) != cfg.LOOKBACK_WINDOW:
                continue
                
            # 2. ç‰¹å¾æ ‡å‡†åŒ– (ä½¿ç”¨å½“å¹´çš„ scaler)
            x_window_scaled = scaler.transform(x_window_raw)
            # è½¬ä¸º Tensor (Batch=1, Lookback, Features)
            feature_tensor = torch.tensor(x_window_scaled).unsqueeze(0)
            
            # å½“å¤©çš„çœŸå®æ”¶ç›Š (ç”¨äºç»“ç®—)
            y_today = all_returns[t_abs]
            
            # 3. éå†æ‰€æœ‰ç­–ç•¥è·å–å†³ç­–
            for strat in strategies:
                w_prev = current_weights[strat.name]
                
                try:
                    # === æ ¸å¿ƒè°ƒç”¨ ===
                    # å¤šæ€è°ƒç”¨ï¼šä¸åŒç­–ç•¥ä¼šä½¿ç”¨ä¸åŒçš„è¾“å…¥å‚æ•°
                    # ä¼ ç»Ÿç­–ç•¥å¿½ç•¥ feature_tensorï¼Œæ·±åº¦ç­–ç•¥å¿½ç•¥ history_df
                    w_target = strat.get_weights(
                        history_df=history_df_slice, 
                        feature_tensor=feature_tensor
                    )
                except Exception as e:
                    # å¦‚æœç­–ç•¥å´©æºƒ (æå°‘è§)ï¼Œä¿æŒä»“ä½ä¸å˜æˆ–ç©ºä»“
                    # print(f"Error in {strat.name}: {e}")
                    w_target = w_prev
                
                # 4. ç»“ç®— PnL
                # è®¡ç®—æ¢æ‰‹
                turnover = np.sum(np.abs(w_target - w_prev))
                cost = turnover * cfg.COST_COEFF
                
                # è®¡ç®—æ”¶ç›Š (å‡è®¾æ»¡ä»“æˆ–éƒ¨åˆ†ä»“ä½)
                # æ”¶ç›Š = è‚¡ç¥¨æ”¶ç›Š + ç°é‡‘æ”¶ç›Š(0) - äº¤æ˜“æˆæœ¬
                gross_ret = np.sum(w_target * y_today)
                net_ret = gross_ret - cost
                
                # è®°å½•
                results[strat.name].append(net_ret)
                turnovers[strat.name].append(turnover)
                
                # æ›´æ–°æŒä»“
                current_weights[strat.name] = w_target

    # ==========================================
    # 4. ç»“æœæ±‡æ€»ä¸å¯è§†åŒ–
    # ==========================================
    print("\nğŸ“Š è®¡ç®—æœ€ç»ˆæŒ‡æ ‡æ’è¡Œæ¦œ...")
    
    metrics_list = []
    equity_curves = {}
    
    # è·å–æ—¥æœŸç´¢å¼• (ç”¨äºç»˜å›¾)
    # æ³¨æ„ï¼šresults åˆ—è¡¨å¯èƒ½æ¯” dates å°‘ä¸€ç‚¹ç‚¹ï¼ˆå› ä¸ºå¼€å¤´ lookback è·³è¿‡ï¼‰
    # æˆ‘ä»¬å–æœ€å N ä¸ªæ—¥æœŸå¯¹é½
    n_days = len(results['1/N Benchmark'])
    plot_dates = dates[-n_days:]
    
    for strat in strategies:
        ret_seq = np.array(results[strat.name])
        to_seq = np.array(turnovers[strat.name])
        
        # è®¡ç®—æŒ‡æ ‡
        m = calculate_metrics(ret_seq, to_seq, strat.name)
        metrics_list.append(m)
        
        # è®¡ç®—å‡€å€¼æ›²çº¿
        equity = (1 + ret_seq).cumprod()
        equity_curves[strat.name] = pd.Series(equity, index=plot_dates)
        
    # ç”Ÿæˆ DataFrame
    metrics_df = pd.DataFrame(metrics_list)
    # æŒ‰ Sortino æ’åº
    metrics_df = metrics_df.sort_values("Sortino", ascending=False)
    
    print("\nğŸ† å…¨ç­–ç•¥å›æµ‹ç»“æœ (2018 - End):")
    print(metrics_df.to_string(index=False))
    
    # ä¿å­˜ CSV
    metrics_df.to_csv("rolling_backtest_metrics.csv", index=False)
    metrics_df.to_csv("results/rolling_backtest_metrics.csv", index=False)
    
    # --- ä¿å­˜åŸå§‹åºåˆ— (New) ---
    print("\nğŸ’¾ ä¿å­˜åŸå§‹åºåˆ—æ•°æ®...")
    try:
        # æ„é€  DataFrame (ä½¿ç”¨å¯¹é½åçš„æ—¥æœŸç´¢å¼•)
        returns_df = pd.DataFrame(results, index=plot_dates)
        turnovers_df = pd.DataFrame(turnovers, index=plot_dates)
        
        returns_df.to_csv("results/backtest_daily_returns.csv")
        turnovers_df.to_csv("results/backtest_daily_turnovers.csv")
        print("   -> results/backtest_daily_returns.csv (æ—¥æ”¶ç›Šç‡)")
        print("   -> results/backtest_daily_turnovers.csv (æ—¥æ¢æ‰‹ç‡)")
    except Exception as e:
        print(f"âš ï¸ ä¿å­˜åŸå§‹åºåˆ—å¤±è´¥: {e}")

    # --- ç»˜å›¾ ---
    plt.figure(figsize=(14, 8))
    
    # å®šä¹‰é¢œè‰²å’Œçº¿å‹ï¼Œçªå‡ºæ˜¾ç¤º Diff-MPO
    for strat_name, curve in equity_curves.items():
        if "Diff-MPO" in strat_name:
            plt.plot(curve, label=strat_name, linewidth=2.5, color='#d62728', alpha=1.0) # çº¢è‰²åŠ ç²—
        elif "1/N" in strat_name:
            plt.plot(curve, label=strat_name, linewidth=2.0, color='black', linestyle='--', alpha=0.7)
        else:
            plt.plot(curve, label=strat_name, linewidth=1.0, alpha=0.5)
            
    plt.title('Grand Challenge: Diff-MPO vs Traditional Strategies (Walk-Forward)', fontsize=16)
    plt.ylabel('Cumulative Wealth')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    
    save_path = "results/grand_challenge_wealth_curves.png"
    plt.savefig(save_path, dpi=300)
    print(f"\nğŸ“ˆ å‡€å€¼æ›²çº¿å·²ä¿å­˜è‡³: {save_path}")

if __name__ == "__main__":
    run_comprehensive_backtest()
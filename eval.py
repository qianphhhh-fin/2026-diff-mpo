import torch
import numpy as np
import pandas as pd
import cvxpy as cp
import matplotlib.pyplot as plt
import scipy.cluster.hierarchy as sch
from scipy.spatial.distance import squareform
from tqdm import tqdm
import matplotlib.dates as mdates  # <--- 1. æ–°å¢ï¼šå¼•å…¥æ—¥æœŸæ ¼å¼åŒ–åº“
from config import cfg
from data_loader import load_and_process_data
from model import MPO_Network
from mpo_solver import DifferentiableMPO

# è®¾ç½®ç»˜å›¾é£æ ¼
plt.style.use('seaborn-v0_8')

# ==========================================
# 1. ç­–ç•¥åŸºç±»ä¸é€šç”¨å‡½æ•°
# ==========================================
class BaseStrategy:
    def __init__(self, name):
        self.name = name
    
    def get_weights(self, prices_df, current_weights, context_data=None):
        """
        è¾“å…¥:
            prices_df: æˆªæ­¢åˆ° t æ—¶åˆ»çš„å†å²ä»·æ ¼/æ”¶ç›Šæ•°æ®
            current_weights: å½“å‰æŒä»“ (t-1)
            context_data: ç¥ç»ç½‘ç»œéœ€è¦çš„é¢å¤– Tensor æ•°æ® (Batch)
        è¾“å‡º:
            target_weights: t æ—¶åˆ»çš„ç›®æ ‡ä»“ä½ (N,)
        """
        raise NotImplementedError

def calculate_turnover_cost(w_new, w_old, cost_rate=0.0005):
    turnover = np.sum(np.abs(w_new - w_old))
    return turnover * cost_rate, turnover

# ==========================================
# 2. æ·±åº¦å­¦ä¹ ç­–ç•¥ç»„
# ==========================================
class DeepStrategy(BaseStrategy):
    def __init__(self, name, model_path, mode='mpo'):
        super().__init__(name)
        self.mode = mode
        self.device = cfg.DEVICE
        
        # åŠ è½½æ¨¡å‹
        self.model = MPO_Network().to(self.device).double()
        # å…è®¸åŠ è½½éƒ¨åˆ†æƒé‡ (å› ä¸º baseline æ¨¡å‹ç»“æ„å¯èƒ½ç•¥æœ‰å·®å¼‚ï¼Œä½†è¿™é‡Œæˆ‘ä»¬ç»“æ„ç»Ÿä¸€)
        state_dict = torch.load(model_path, map_location=self.device)
        self.model.load_state_dict(state_dict)
        self.model.eval()
        
        # å¦‚æœæ˜¯ Two-Stageï¼Œéœ€è¦ä¸€ä¸ªç‹¬ç«‹çš„ Solver
        if mode == 'two_stage':
            self.solver_layer = DifferentiableMPO() # å¤ç”¨ Solver
            
    def get_weights(self, prices_df, current_weights, context_data):
        x_tensor, _ = context_data
        x_tensor = x_tensor.to(self.device).double()
        w_prev = torch.tensor(current_weights, device=self.device, dtype=torch.double).unsqueeze(0)
        
        with torch.no_grad():
            if self.name == 'Ours (Diff-MPO)':
                # ç›´æ¥ç«¯åˆ°ç«¯è¾“å‡º
                w_plan, _, _ = self.model(x_tensor, w_prev)
                # w_plan æ˜¯ (Batch, Horizon, Assets)ï¼Œæˆ‘ä»¬å–ç¬¬ä¸€æ­¥ t=0
                return w_plan[0, 0, :].cpu().numpy()
            
            elif self.name == 'Two-Stage (MSE)':
                # 1. é¢„æµ‹ mu (æ¨¡å‹ä¸ç®¡ Solver)
                _, (h_n, _) = self.model.lstm(x_tensor)
                context = h_n[-1]
                mu_pred = self.model.mu_head(context).view(1, cfg.PREDICT_HORIZON, cfg.NUM_ASSETS)
                
                # 2. é¢„æµ‹ L (è¿™é‡Œå…¶å® MSE æ¨¡å‹ä¹Ÿé¢„æµ‹äº† Lï¼Œè™½ç„¶è®­ç»ƒæ²¡ç”¨åˆ°ï¼Œä½†å¯ä»¥æ‹¿æ¥ç”¨)
                # æˆ–è€…ç”¨å†å²åæ–¹å·®ä»£æ›¿ã€‚ä¸ºäº†å…¬å¹³ï¼Œæˆ‘ä»¬ç”¨æ¨¡å‹é¢„æµ‹çš„ L
                L_flat = self.model.L_head(context)
                L_pred = L_flat.view(1, cfg.PREDICT_HORIZON, cfg.NUM_ASSETS, cfg.NUM_ASSETS)
                
                # å¤„ç† L åˆæ³•æ€§
                mask = torch.tril(torch.ones_like(L_pred))
                L_pred = L_pred * mask
                diag_mask = torch.eye(cfg.NUM_ASSETS, device=self.device).view(1, 1, cfg.NUM_ASSETS, cfg.NUM_ASSETS)
                L_pred = L_pred + diag_mask * (torch.nn.functional.softplus(L_pred) + 1e-5 - L_pred)

                # 3. æ˜¾å¼è°ƒç”¨ Solver (åœ¨ CPU ä¸Šè§£)
                # Two-Stage çš„æ ¸å¿ƒåœ¨äºï¼šé¢„æµ‹æ˜¯ç‹¬ç«‹çš„ï¼Œä½†æ‰§è¡Œæ—¶ä¾ç„¶ç”¨ MPO
                w_plan = self.solver_layer(mu_pred.cpu(), L_pred.cpu(), w_prev.cpu())
                return w_plan[0, 0, :].detach().numpy()
                
            elif self.name == 'Neural Risk Parity':
                # åªç”¨é¢„æµ‹çš„æ³¢åŠ¨ç‡
                _, (h_n, _) = self.model.lstm(x_tensor)
                L_flat = self.model.L_head(h_n[-1])
                L_pred = L_flat.view(1, cfg.PREDICT_HORIZON, cfg.NUM_ASSETS, cfg.NUM_ASSETS)
                
                # ç®—åæ–¹å·® Sigma = L @ L.T
                # å–ç¬¬ä¸€ä¸ªæ—¶é—´æ­¥ t=0
                L_t0 = L_pred[0, 0, :, :]
                Sigma_t0 = L_t0 @ L_t0.T
                
                # é£é™©å¹³ä»·: w ~ 1 / sqrt(diag(Sigma))
                vols = torch.sqrt(torch.diagonal(Sigma_t0))
                raw_w = 1.0 / (vols + 1e-6)
                return (raw_w / raw_w.sum()).cpu().numpy()

# ==========================================
# 3. ç»å…¸ä¼˜åŒ–ç­–ç•¥ç»„ (Convex Optimization)
# ==========================================
class OptimizationStrategy(BaseStrategy):
    def __init__(self, name, lookback=60):
        super().__init__(name)
        self.lookback = lookback
        
    def get_weights(self, prices_df, current_weights, context_data=None):
        # è·å–è¿‡å» N å¤©çš„æ”¶ç›Šç‡æ•°æ®
        returns = prices_df.iloc[-self.lookback:].values
        
        # 1. å‡å€¼ä¸åæ–¹å·®ä¼°è®¡
        mu_est = np.mean(returns, axis=0)
        cov_est = np.cov(returns.T)
        
        N = len(mu_est)
        w = cp.Variable(N)
        
        if self.name == 'Mean-Variance':
            # Max mu*w - lambda * w*Sigma*w
            risk_aversion = 1.0
            ret = mu_est @ w
            risk = cp.quad_form(w, cov_est)
            obj = cp.Maximize(ret - risk_aversion * risk)
            constraints = [cp.sum(w) == 1, w >= 0]
            
        elif self.name == 'Global Min Var':
            # Min w*Sigma*w
            risk = cp.quad_form(w, cov_est)
            obj = cp.Minimize(risk)
            constraints = [cp.sum(w) == 1, w >= 0]
            
        elif self.name == 'Mean-CVaR':
            # æœ€å°åŒ– CVaR (95%)
            # å¼•å…¥è¾…åŠ©å˜é‡
            # CVaR = alpha + 1/(1-c) * mean(max(loss - alpha, 0))
            # Loss = - returns @ w
            alpha = cp.Variable()
            # æ¨¡æ‹Ÿæ ·æœ¬åœºæ™¯
            samples = returns # (T, N)
            losses = - samples @ w
            
            cvar_term = alpha + (1.0 / (0.05 * self.lookback)) * cp.sum(cp.pos(losses - alpha))
            obj = cp.Minimize(cvar_term)
            constraints = [cp.sum(w) == 1, w >= 0]
            
        else:
            return np.ones(N) / N
            
        prob = cp.Problem(obj, constraints)
        try:
            prob.solve(solver=cp.ECOS)
            if w.value is None: return current_weights # æ±‚è§£å¤±è´¥ä¿æŒä¸åŠ¨
            return np.clip(w.value, 0, 1) # ä¿®æ­£æ•°å€¼è¯¯å·®
        except:
            return current_weights

# ==========================================
# 4. è§„åˆ™ä¸ç°ä»£ç­–ç•¥ç»„ (HRP, Momentum, 1/N)
# ==========================================
class RuleStrategy(BaseStrategy):
    def get_weights(self, prices_df, current_weights, context_data=None):
        N = prices_df.shape[1]
        
        if self.name == '1/N':
            return np.ones(N) / N
            
        elif self.name == 'Vanilla Risk Parity':
            # w ~ 1/std
            returns = prices_df.iloc[-60:].values
            vols = np.std(returns, axis=0)
            w = 1.0 / (vols + 1e-6)
            return w / np.sum(w)
            
        elif self.name == 'Factor Momentum':
            # è¿‡å» 20 å¤©æ”¶ç›Šç‡ä¸ºæ­£çš„ï¼Œå¹³åˆ†æƒé‡ï¼›å¦åˆ™ä¸º 0
            # è¿™æ˜¯ä¸€ä¸ª Long-Only çš„åŠ¨é‡å®ç°
            moms = prices_df.iloc[-20:].mean().values
            # ç®€å•çš„ Signal: > 0 ä¹°å…¥
            signal = (moms > 0).astype(float)
            if signal.sum() == 0: return np.ones(N)/N # å…¨è·Œå°±èººå¹³
            return signal / signal.sum()

class HRPStrategy(BaseStrategy):
    """ Hierarchical Risk Parity (Lopez de Prado) """
    def get_weights(self, prices_df, current_weights, context_data=None):
        returns = prices_df.iloc[-60:]
        corr = returns.corr().values
        cov = returns.cov().values
        
        # 1. èšç±» (Hierarchical Clustering)
        dist = np.sqrt((1 - corr) / 2)
        link = sch.linkage(squareform(dist), 'single')
        
        # 2. æ’åº (Quasi-Diagonalization)
        # è¿™é‡Œç®€åŒ–ï¼šç›´æ¥ç”¨ sch.dendrogram å¾—åˆ°çš„å¶å­é¡ºåº
        sort_ix = sch.dendrogram(link, no_plot=True)['leaves']
        
        # 3. é€’å½’äºŒåˆ† (Recursive Bisection)
        # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–ç‰ˆçš„ HRP æ ¸å¿ƒé€»è¾‘ï¼šè‡ªé¡¶å‘ä¸‹åˆ†é…é£é™©
        w = pd.Series(1, index=sort_ix)
        
        # æ ¸å¿ƒé€»è¾‘å¤ªé•¿ï¼Œè¿™é‡Œç”¨ Inverse Variance æ›¿ä»£ Cluster å†…éƒ¨æƒé‡
        # çœŸå® HRP æ¯”è¾ƒå¤æ‚ï¼Œè¿™é‡Œç”¨ "Hierarchical Inverse Variance" è¿‘ä¼¼
        # é‡æ–°æ’åˆ— Cov
        cov_sorted = cov[sort_ix][:, sort_ix]
        
        # ç®€å•å®ç°ï¼šHRP çš„æ ¸å¿ƒæ€æƒ³æ˜¯ç›¸ä¼¼èµ„äº§åˆ†é…ç›¸ä¼¼æƒé‡
        # è¿™é‡Œé€€åŒ–ä¸º IVP (Inverse Variance) ä½†åœ¨ Cluster å±‚é¢
        # ä¸ºäº†ä»£ç ç®€æ´ï¼Œæˆ‘ä»¬ä½¿ç”¨ IVP ä½œä¸º HRP çš„è¿‘ä¼¼ (Common simplification)
        ivp = 1. / np.diag(cov)
        ivp /= ivp.sum()
        return ivp 

# ==========================================
# 5. å›æµ‹ä¸»å¼•æ“
# ==========================================
def run_backtest():
    print("âš”ï¸ å¼€å¯å›æµ‹ç«æŠ€åœº (Backtest Arena) ...")
    
    # 1. å‡†å¤‡æ•°æ®
    _, test_loader, scaler = load_and_process_data()
    df = pd.read_csv(cfg.DATA_PATH, index_col=0, parse_dates=True)
    split_date = pd.Timestamp(cfg.TRAIN_SPLIT_DATE)
    
    # æå–æµ‹è¯•é›†æœŸé—´çš„æ•°æ®
    test_returns_df = df.loc[df.index >= split_date, cfg.ASSETS]
    
    # 2. åˆå§‹åŒ–æ‰€æœ‰ç­–ç•¥ (ä¿æŒä¸å˜)
    strategies = [
        DeepStrategy('Ours (Diff-MPO)', 'models/diff_mpo_sharpe.pth', mode='mpo'),
        DeepStrategy('Two-Stage (MSE)', 'models/baseline_mse_model.pth', mode='two_stage'),
        DeepStrategy('Neural Risk Parity', 'models/baseline_vol_model.pth', mode='nrp'),
        OptimizationStrategy('Mean-Variance'),
        OptimizationStrategy('Global Min Var'),
        OptimizationStrategy('Mean-CVaR'),
        RuleStrategy('1/N'),
        RuleStrategy('Vanilla Risk Parity'),
        RuleStrategy('Factor Momentum'),
    ]
    
    results = {s.name: {'wealth': [cfg.INIT_WEALTH], 'turnover': []} for s in strategies}
    current_weights = {s.name: np.ones(cfg.NUM_ASSETS)/cfg.NUM_ASSETS for s in strategies}
    
    print(f"   æµ‹è¯•é›†é•¿åº¦: {len(test_returns_df)} å¤©")
    print(f"   äº¤æ˜“æˆæœ¬ (å•è¾¹): {cfg.COST_COEFF}")
    
    full_w_plans = {s.name: [] for s in strategies}
    
    # --- ç¬¬ä¸€é˜¶æ®µï¼šç”Ÿæˆæ‰€æœ‰ç­–ç•¥çš„æƒé‡åºåˆ— (ä¿æŒä¸å˜) ---
    print("   æ­£åœ¨ç”Ÿæˆå†³ç­–åºåˆ—...")
    for batch_idx, (x_batch, _) in enumerate(tqdm(test_loader)):
        for i in range(x_batch.size(0)):
            global_idx = batch_idx * cfg.BATCH_SIZE + i
            if global_idx >= len(test_returns_df) - 1: break
            
            current_date_idx = global_idx
            if current_date_idx < 60:
                history_slice = test_returns_df.iloc[:60]
            else:
                history_slice = test_returns_df.iloc[current_date_idx-60 : current_date_idx]
            
            x_sample = x_batch[i].unsqueeze(0)
            
            for strat in strategies:
                w_curr = current_weights[strat.name]
                if isinstance(strat, DeepStrategy):
                    w_target = strat.get_weights(None, w_curr, context_data=(x_sample, None))
                else:
                    w_target = strat.get_weights(history_slice, w_curr)
                full_w_plans[strat.name].append(w_target)
                current_weights[strat.name] = w_target
    
    # --- ç¬¬äºŒé˜¶æ®µï¼šç»Ÿä¸€è®¡ç®—å‡€å€¼ ---
    print("   æ­£åœ¨è®¡ç®—å‡€å€¼ä¸å½’å› ...")
    n_days = len(full_w_plans['1/N'])
    
    # <--- 2. ä¿®æ”¹ï¼šè·å–å¯¹åº”çš„æ—¥æœŸåºåˆ— --->
    # realized_ret æ˜¯ä»ç¬¬ 0 å¤©å¼€å§‹çš„
    # ä½†ç”±äºæˆ‘ä»¬è®¡ç®—é€»è¾‘æ˜¯ r_t1 = realized_ret[1:]
    # æ‰€ä»¥å‡€å€¼æ›²çº¿æ˜¯ä»ç¬¬ 1 å¤©å¼€å§‹ç´¯ç§¯çš„
    realized_ret = test_returns_df.iloc[:n_days].values
    full_dates = test_returns_df.index[:n_days] # è·å–å®Œæ•´æ—¥æœŸç´¢å¼•
    plot_dates = full_dates[1:] # å¯¹é½å‡€å€¼æ›²çº¿çš„æ—¥æœŸ (å»æ‰ç¬¬ä¸€å¤©)
    
    metrics = []
    
    for strat_name in full_w_plans:
        weights_seq = np.array(full_w_plans[strat_name])
        
        w_t = weights_seq[:-1]
        r_t1 = realized_ret[1:]
        
        gross_ret = (w_t * r_t1).sum(axis=1)
        
        w_diff = np.abs(w_t[1:] - w_t[:-1])
        turnover_dynamic = w_diff.sum(axis=1)
        first_turnover = np.sum(np.abs(w_t[0]))
        turnover = np.insert(turnover_dynamic, 0, first_turnover)
        
        cost = turnover * cfg.COST_COEFF
        net_ret = gross_ret - cost # ä¹‹å‰ä¿®å¤çš„ bugï¼Œä¸è¦åˆ‡ç‰‡
        
        wealth = np.cumprod(1 + net_ret)
        results[strat_name]['wealth'] = wealth
        
        ann_ret = np.mean(net_ret) * 252
        ann_vol = np.std(net_ret) * np.sqrt(252)
        sharpe = (ann_ret - 0.02) / (ann_vol + 1e-6)
        
        cum_max = np.maximum.accumulate(wealth)
        drawdown = (wealth - cum_max) / cum_max
        max_dd = drawdown.min()
        avg_turnover = np.mean(turnover)
        
        metrics.append({
            'Strategy': strat_name,
            'Ann Return': f"{ann_ret:.2%}",
            'Sharpe': f"{sharpe:.2f}",
            'Max DD': f"{max_dd:.2%}",
            'Turnover': f"{avg_turnover:.2%}",
            '_sort_key': sharpe
        })
        
    metrics_df = pd.DataFrame(metrics).sort_values('_sort_key', ascending=False).drop(columns='_sort_key')
    print("\nğŸ† å›æµ‹ç»“æœæ’è¡Œæ¦œ (Test Set):")
    print(metrics_df)
    metrics_df.to_csv('backtest_metrics.csv', index=False)
    
    # --- 3. ä¿®æ”¹ï¼šç»˜å›¾éƒ¨åˆ† ---
    plt.figure(figsize=(14, 8)) #ç¨å¾®å®½ä¸€ç‚¹
    
    for strat_name in results:
        wealth = results[strat_name]['wealth']
        
        # ä¼˜åŒ–ï¼šåªç»™å‰å‡ ååŠ ç²—ï¼Œå…¶ä»–çš„ç»†çº¿ï¼Œé¿å…å¤ªä¹±
        if 'Ours' in strat_name:
            lw = 2.5
            alpha = 1.0
            zorder = 10 # ä¿è¯ç”»åœ¨æœ€ä¸Šå±‚
        elif '1/N' in strat_name:
            lw = 2.0
            alpha = 0.8
            zorder = 5
        else:
            lw = 1.0
            alpha = 0.6
            zorder = 1
            
        plt.plot(plot_dates, wealth, label=strat_name, linewidth=lw, alpha=alpha, zorder=zorder)
        
    plt.title('Cumulative Wealth: Diff-MPO vs Benchmarks', fontsize=14)
    plt.ylabel('Wealth (Start=1.0)', fontsize=12)
    plt.xlabel('Date', fontsize=12)
    
    # æ—¥æœŸæ ¼å¼åŒ–ç¾åŒ–
    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
    plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=6)) # æ¯6ä¸ªæœˆæ ‡ä¸€ä¸ªåˆ»åº¦
    plt.gcf().autofmt_xdate() # è‡ªåŠ¨æ—‹è½¬æ—¥æœŸæ ‡ç­¾
    
    plt.legend(loc='upper left', fontsize=10, frameon=True, framealpha=0.9)
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    
    save_path = 'backtest_wealth_curve.png'
    plt.savefig(save_path, dpi=300) # æé«˜åˆ†è¾¨ç‡
    print(f"\nğŸ“ˆ å‡€å€¼æ›²çº¿å·²ä¿å­˜è‡³ {save_path} (Xè½´å·²æ˜¾ç¤ºçœŸå®æ—¥æœŸ)")

if __name__ == "__main__":
    run_backtest()
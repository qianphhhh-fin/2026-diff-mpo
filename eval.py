import torch
import numpy as np
import pandas as pd
import cvxpy as cp
import matplotlib.pyplot as plt
from tqdm import tqdm
import matplotlib.dates as mdates
import sys

from config import cfg
from data_loader import load_and_process_data
from model import MPO_Network
from mpo_solver import DifferentiableMPO

# è®¾ç½®ç»˜å›¾é£æ ¼
plt.style.use('seaborn-v0_8')

# ==========================================
# 1. ç­–ç•¥åŸºç±»
# ==========================================
class BaseStrategy:
    def __init__(self, name):
        self.name = name
    
    def get_weights(self, prices_df, current_weights, context_data=None):
        raise NotImplementedError

# ==========================================
# 2. æ·±åº¦å­¦ä¹ ç­–ç•¥ç»„
# ==========================================
class DeepStrategy(BaseStrategy):
    def __init__(self, name, model_path, mode='mpo'):
        super().__init__(name)
        self.mode = mode
        self.device = cfg.DEVICE
        
        # åŠ è½½æ¨¡å‹
        self.model = MPO_Network().to(self.device).double()
        try:
            state_dict = torch.load(model_path, map_location=self.device)
            self.model.load_state_dict(state_dict)
            print(f"âœ… [DeepStrategy] æˆåŠŸåŠ è½½æ¨¡å‹: {name}")
        except Exception as e:
            print(f"âš ï¸ [DeepStrategy] æ— æ³•åŠ è½½æ¨¡å‹ {name}: {e}")
            # å¦‚æœåŠ è½½å¤±è´¥ï¼Œä¸è¦è®©å®ƒè·‘ï¼Œç›´æ¥æŠ¥é”™ï¼Œé¿å…æµªè´¹æ—¶é—´
            raise RuntimeError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨æˆ–æŸå: {model_path}")

        self.model.eval()
        
        if mode == 'two_stage':
            self.solver_layer = DifferentiableMPO() 
            
    def get_weights(self, prices_df, current_weights, context_data):
        # context_data is (x_window, _)
        x_tensor, _ = context_data
        
        # å¢åŠ ç»´åº¦æ£€æŸ¥
        if x_tensor.shape[-1] != cfg.INPUT_FEATURE_DIM:
            raise ValueError(f"è¾“å…¥ç‰¹å¾ç»´åº¦é”™è¯¯! æ¨¡å‹æœŸæœ› {cfg.INPUT_FEATURE_DIM}, å®é™…å¾—åˆ° {x_tensor.shape[-1]}")

        x_tensor = x_tensor.to(self.device).double()
        w_prev = torch.tensor(current_weights, device=self.device, dtype=torch.double).unsqueeze(0)
        
        with torch.no_grad():
            if 'Diff-MPO' in self.name or 'Ours' in self.name:
                w_plan, _, _ = self.model(x_tensor, w_prev)
                return w_plan[0, 0, :].cpu().numpy()
            
            elif 'Two-Stage' in self.name:
                _, (h_n, _) = self.model.lstm(x_tensor)
                context = h_n[-1]
                mu_pred = self.model.mu_head(context).view(1, cfg.PREDICT_HORIZON, cfg.NUM_ASSETS)
                L_flat = self.model.L_head(context)
                L_pred = L_flat.view(1, cfg.PREDICT_HORIZON, cfg.NUM_ASSETS, cfg.NUM_ASSETS)
                
                # æ„é€ æ­£å®šçŸ©é˜µ
                mask = torch.tril(torch.ones_like(L_pred))
                L_pred = L_pred * mask
                diag_mask = torch.eye(cfg.NUM_ASSETS, device=self.device).view(1, 1, cfg.NUM_ASSETS, cfg.NUM_ASSETS)
                L_pred = L_pred + diag_mask * (torch.nn.functional.softplus(L_pred) + 1e-5 - L_pred)

                w_plan = self.solver_layer(mu_pred.cpu(), L_pred.cpu(), w_prev.cpu())
                return w_plan[0, 0, :].detach().numpy()
                
            elif 'Neural Risk Parity' in self.name:
                _, (h_n, _) = self.model.lstm(x_tensor)
                L_flat = self.model.L_head(h_n[-1])
                L_pred = L_flat.view(1, cfg.PREDICT_HORIZON, cfg.NUM_ASSETS, cfg.NUM_ASSETS)
                L_t0 = L_pred[0, 0, :, :]
                Sigma_t0 = L_t0 @ L_t0.T
                vols = torch.sqrt(torch.diagonal(Sigma_t0))
                raw_w = 1.0 / (vols + 1e-6)
                return (raw_w / raw_w.sum()).cpu().numpy()

# ==========================================
# 3. ç»å…¸ä¼˜åŒ–ç­–ç•¥ç»„ (Strict Mode)
# ==========================================
class OptimizationStrategy(BaseStrategy):
    def __init__(self, name, lookback=126, lambda_cost=0.0):
        super().__init__(name)
        self.lookback = lookback
        self.lambda_cost = lambda_cost
        
    def get_weights(self, history_df, current_weights, context_data=None):
        """
        history_df: åŒ…å«è¿‡å» N å¤©çš„æ”¶ç›Šç‡æ•°æ® (indexæ˜¯æ—¥æœŸ)
        """
        # 1. æ•°æ®æ£€æŸ¥
        if history_df is None or len(history_df) < self.lookback:
            # å¦‚æœæ˜¯åˆšå¼€å§‹å›æµ‹ï¼Œæ•°æ®ä¸è¶³ï¼Œå¯ä»¥ä½¿ç”¨ 1/Nï¼Œä½†ä¸åº”è¯¥ä¸€ç›´å‘ç”Ÿ
            return np.ones(cfg.NUM_ASSETS) / cfg.NUM_ASSETS
            
        # æˆªå–çª—å£
        returns_window = history_df.iloc[-self.lookback:].values
        
        # æ£€æŸ¥ NaN
        if np.isnan(returns_window).any():
            # å°è¯•å¡«å……
            returns_window = np.nan_to_num(returns_window)
            
        # 2. å‚æ•°ä¼°è®¡
        mu_est = np.mean(returns_window, axis=0)
        cov_est = np.cov(returns_window.T)
        
        # === å…³é”®ä¿®å¤ï¼šåæ–¹å·®æ­£åˆ™åŒ– ===
        # é˜²æ­¢çŸ©é˜µå¥‡å¼‚å¯¼è‡´ Solver å¤±è´¥
        cov_est += 1e-6 * np.eye(len(mu_est))
        
        N = cfg.NUM_ASSETS
        w = cp.Variable(N)
        w_prev = current_weights
        
        # äº¤æ˜“æˆæœ¬é¡¹ (L1 Norm)
        cost_term = cp.norm(w - w_prev, 1) 
        
        # 3. æ„å»ºé—®é¢˜
        if 'Mean-Variance' in self.name:
            risk_aversion = 1.0 # ç¨å¾®é™ä½ä¸€ç‚¹ï¼Œå¤ªé«˜å®¹æ˜“å¯¼è‡´æ•°å€¼é—®é¢˜
            ret = mu_est @ w
            risk = cp.quad_form(w, cov_est)
            obj_expr = ret - risk_aversion * risk
            if self.lambda_cost > 0:
                obj_expr -= self.lambda_cost * cost_term
            objective = cp.Maximize(obj_expr)
            
        elif 'Global Min Var' in self.name:
            risk = cp.quad_form(w, cov_est)
            obj_expr = risk
            if self.lambda_cost > 0:
                obj_expr += self.lambda_cost * cost_term
            objective = cp.Minimize(obj_expr)
            
        elif 'Mean-CVaR' in self.name:
            # CVaR æ¯”è¾ƒéš¾è§£ï¼Œéœ€è¦å¼•å…¥è¾…åŠ©å˜é‡
            # CVaR(alpha) = alpha + 1/(1-c) * mean(max(-w*r - alpha, 0))
            # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå¦‚æœä¸æ”¶æ•›ç›´æ¥æŠ›é”™
            alpha = cp.Variable()
            # æ³¨æ„ï¼šreturns_window æ˜¯ (T, N)ï¼Œè¿™é‡Œè¦å˜æˆ (T,)
            port_returns = returns_window @ w 
            losses = -port_returns
            
            cvar_limit = 0.95
            cvar_term = alpha + (1.0 / ((1.0 - cvar_limit) * self.lookback)) * cp.sum(cp.pos(losses - alpha))
            
            obj_expr = cvar_term
            if self.lambda_cost > 0:
                obj_expr += self.lambda_cost * cost_term
            objective = cp.Minimize(obj_expr)
            
        else:
            raise ValueError(f"æœªçŸ¥çš„ä¼˜åŒ–ç­–ç•¥: {self.name}")
            
        # çº¦æŸæ¡ä»¶
        constraints = [
            cp.sum(w) == 1, 
            w >= 0 
        ]
        
        prob = cp.Problem(objective, constraints)
        
        # 4. æ±‚è§£ (Strict Mode)
        try:
            # å°è¯• ECOSï¼Œå¦‚æœå¤±è´¥å°è¯• SCS
            prob.solve(solver=cp.ECOS, abstol=1e-5)
            
            if prob.status not in [cp.OPTIMAL, cp.OPTIMAL_INACCURATE]:
                # å¦‚æœ ECOS å¤±è´¥ï¼Œå°è¯• SCS
                prob.solve(solver=cp.SCS, eps=1e-4)
            
            if prob.status not in [cp.OPTIMAL, cp.OPTIMAL_INACCURATE]:
                raise ValueError(f"Solver Status: {prob.status}")
                
            if w.value is None:
                raise ValueError("Solver returned None weights")
                
            # å½’ä¸€åŒ–å¹¶å¤„ç†å¾®å°è´Ÿå€¼
            res_w = np.clip(w.value, 0, 1)
            return res_w / res_w.sum()
            
        except Exception as e:
            # === ä¸¥å‰æŠ¥é”™ ===
            print(f"\nâŒ [CRITICAL ERROR] ç­–ç•¥ {self.name} ä¼˜åŒ–å¤±è´¥ï¼")
            print(f"   åŸå› : {e}")
            print(f"   æ—¥æœŸç´¢å¼•: æ•°æ®çš„æœ€åä¸€è¡Œæ˜¯ {history_df.index[-1]}")
            print(f"   Cov çŸ©é˜µæ¡ä»¶æ•°: {np.linalg.cond(cov_est)}")
            raise e # ç›´æ¥æŠ›å‡ºï¼Œç»ˆæ­¢ç¨‹åº

# ==========================================
# 4. è§„åˆ™ç­–ç•¥
# ==========================================
class RuleStrategy(BaseStrategy):
    def get_weights(self, history_df, current_weights, context_data=None):
        N = cfg.NUM_ASSETS
        
        if '1/N' in self.name:
            return np.ones(N) / N
            
        elif 'Vanilla Risk Parity' in self.name:
            # è¿‡å» 1 å¹´çš„æ³¢åŠ¨ç‡å€’æ•°
            # è¿™é‡Œçš„ history_df å·²ç»æ˜¯ returns
            window = 252
            if len(history_df) < window:
                window = len(history_df)
                
            returns = history_df.iloc[-window:].values
            vols = np.std(returns, axis=0)
            
            # é˜²é™¤é›¶
            vols[vols < 1e-6] = 1e-6
            
            w = 1.0 / vols
            return w / np.sum(w)
            
        elif 'Factor Momentum' in self.name:
            # ç®€å•çš„æˆªé¢åŠ¨é‡ï¼šä¹°è¿‡å» 60 å¤©æ¶¨å¹…æœ€å¥½çš„ 3 ä¸ª
            ret_accum = history_df.iloc[-60:].sum()
            # é€‰ top 3
            top_k_indices = ret_accum.argsort()[-3:]
            w = np.zeros(N)
            w[top_k_indices] = 1.0 / 3.0
            return w

# ==========================================
# 5. å›æµ‹ä¸»å¼•æ“
# ==========================================
def run_backtest():
    print("âš”ï¸ å¼€å¯å›æµ‹ç«æŠ€åœº (Strict Mode Debugging) ...")
    
    # 1. å‡†å¤‡æ•°æ®
    _, test_loader, scaler = load_and_process_data()
    
    # è¯»å–åŸå§‹ CSV (ç”¨äº Optimization Strategy çš„è¾“å…¥)
    df_raw = pd.read_csv(cfg.DATA_PATH, index_col=0, parse_dates=True)
    # åªä¿ç•™èµ„äº§åˆ—ç”¨äºè®¡ç®—å›æŠ¥
    df_assets_ret = df_raw[cfg.ASSETS]
    
    # ç¡®å®šæµ‹è¯•é›†èµ·å§‹ç‚¹
    split_date = pd.Timestamp(cfg.TRAIN_SPLIT_DATE)
    
    # 2. åˆå§‹åŒ–ç­–ç•¥
    strategies = [
        # Deep Models
        DeepStrategy('Ours (Diff-MPO)', 'models/diff_mpo_sharpe.pth', mode='mpo'),
        DeepStrategy('Two-Stage (MSE)', 'models/baseline_mse_model.pth', mode='two_stage'),
        DeepStrategy('Neural Risk Parity', 'models/baseline_vol_model.pth', mode='nrp'),
        
        # Optimization Models (Classic)
        OptimizationStrategy('Mean-Variance', lookback=60, lambda_cost=0.0),
        OptimizationStrategy('Global Min Var', lookback=60, lambda_cost=0.0),
        # Mean-CVaR è®¡ç®—å¤ªæ…¢ä¸”å®¹æ˜“æ— è§£ï¼Œæš‚æ—¶æ³¨é‡Šæ‰ï¼Œå…ˆè°ƒé€šä¸Šé¢ä¸¤ä¸ª
        # OptimizationStrategy('Mean-CVaR', lookback=60, lambda_cost=0.0), 
        
        # Rule Based
        RuleStrategy('1/N'),
        RuleStrategy('Vanilla Risk Parity (1Y)'), 
    ]
    
    results = {s.name: {'wealth': [cfg.INIT_WEALTH], 'turnover': []} for s in strategies}
    current_weights = {s.name: np.ones(cfg.NUM_ASSETS)/cfg.NUM_ASSETS for s in strategies}
    
    full_w_plans = {s.name: [] for s in strategies}
    
    # æ‰¾åˆ°æµ‹è¯•é›†çš„èµ·å§‹ç´¢å¼•
    # æ³¨æ„ï¼šMPODataset çš„ test_loader æ˜¯ä» split_date å¼€å§‹çš„
    # æˆ‘ä»¬éœ€è¦æ‰¾åˆ° df_assets_ret ä¸­å¯¹åº” split_date çš„ä½ç½®
    test_indices = np.where(df_assets_ret.index >= split_date)[0]
    if len(test_indices) == 0:
        raise ValueError("æµ‹è¯•é›†ä¸ºç©ºï¼è¯·æ£€æŸ¥ TRAIN_SPLIT_DATE")
    start_idx = test_indices[0]
    
    print(f"   æµ‹è¯•é›†èµ·å§‹æ—¥æœŸ: {df_assets_ret.index[start_idx]}")
    print(f"   æ€»æ ·æœ¬æ•°: {len(test_loader) * cfg.BATCH_SIZE}")
    
    # --- ç”Ÿæˆå†³ç­–åºåˆ— ---
    print("   æ­£åœ¨ç”Ÿæˆå†³ç­–åºåˆ—...")
    
    # ä¸ºäº†å¯¹é½ï¼Œæˆ‘ä»¬éœ€è¦éå† DataLoader
    # æ¯ä¸ª Batch å¯¹åº” test_loader ä¸­çš„ä¸€æ®µ
    
    global_step = 0
    
    for batch_idx, (x_batch, _) in enumerate(tqdm(test_loader)):
        for i in range(x_batch.size(0)):
            # å½“å‰åœ¨åŸå§‹ DataFrame ä¸­çš„ç»å¯¹ç´¢å¼•
            # æ³¨æ„ï¼štest_loader é‡Œçš„ x æ˜¯å½’ä¸€åŒ–åçš„ï¼Œç”¨äºæ·±åº¦æ¨¡å‹
            # ä¼ ç»Ÿæ¨¡å‹éœ€è¦åŸå§‹æ”¶ç›Šç‡æ•°æ®
            
            curr_abs_idx = start_idx + global_step
            if curr_abs_idx >= len(df_assets_ret): break
            
            current_date = df_assets_ret.index[curr_abs_idx]
            
            # Deep Model Input
            x_sample = x_batch[i].unsqueeze(0)
            
            for strat in strategies:
                w_curr = current_weights[strat.name]
                
                try:
                    if isinstance(strat, DeepStrategy):
                        # æ·±åº¦å­¦ä¹ æ¨¡å‹ä½¿ç”¨ Tensor è¾“å…¥
                        w_target = strat.get_weights(None, w_curr, context_data=(x_sample, None))
                    else:
                        # ä¼ ç»Ÿæ¨¡å‹ä½¿ç”¨å†å² DataFrame åˆ‡ç‰‡
                        # å¿…é¡»åŒ…å«ç›´åˆ° current_date çš„æ•°æ®
                        history_slice = df_assets_ret.iloc[:curr_abs_idx+1] 
                        w_target = strat.get_weights(history_slice, w_curr)
                        
                except Exception as e:
                    print(f"\nâŒ ç­–ç•¥ {strat.name} åœ¨ {current_date} å´©æºƒï¼")
                    print(f"é”™è¯¯ä¿¡æ¯: {e}")
                    sys.exit(1) # å¼ºåˆ¶é€€å‡ºï¼Œæ–¹ä¾¿ä½ çœ‹æŠ¥é”™

                # æ ¼å¼è½¬æ¢ä¸å®‰å…¨æ£€æŸ¥
                w_target = np.array(w_target, dtype=np.float64).reshape(-1)
                
                # å†æ¬¡å½’ä¸€åŒ–é˜²æ­¢æµ®ç‚¹è¯¯å·®
                if w_target.sum() > 1e-6:
                    w_target = w_target / w_target.sum()
                
                full_w_plans[strat.name].append(w_target)
                current_weights[strat.name] = w_target
            
            global_step += 1
    
    # --- è®¡ç®—å‡€å€¼ ---
    print("\n   æ­£åœ¨è®¡ç®—å‡€å€¼ä¸å½’å› ...")
    
    # æˆªå–å®é™…å›æµ‹é•¿åº¦çš„æ”¶ç›Šç‡
    # æ³¨æ„ï¼šw_t å†³å®šçš„æ˜¯ t+1 çš„æ”¶ç›Š
    # full_w_plans é•¿åº¦ä¸º Tï¼Œå¯¹åº”çš„æ”¶ç›Šç‡åº”è¯¥æ˜¯ä» start_idx + 1 å¼€å§‹
    
    n_steps = len(full_w_plans['1/N'])
    realized_ret = df_assets_ret.iloc[start_idx+1 : start_idx+1+n_steps].values
    plot_dates = df_assets_ret.index[start_idx+1 : start_idx+1+n_steps]
    
    # å¦‚æœç”Ÿæˆçš„æƒé‡æ¯”æ”¶ç›Šç‡å¤š1ä¸ªï¼ˆæœ€åä¸€å¤©å†³ç­–ï¼‰ï¼Œæˆªæ–­æƒé‡
    for k in full_w_plans:
        full_w_plans[k] = full_w_plans[k][:len(realized_ret)]
    
    metrics = []
    
    for strat_name in full_w_plans:
        weights_seq = np.array(full_w_plans[strat_name]) # (T, N)
        
        # æ”¶ç›Šè®¡ç®—: R_p = sum(w_{t-1} * r_t)
        # è¿™é‡Œçš„ weights_seq[t] æ˜¯åœ¨ t æ—¶åˆ»åšå‡ºçš„å†³ç­–ï¼Œäº«å— r_{t+1} çš„æ”¶ç›Š
        # ä½†æˆ‘ä»¬åœ¨å¾ªç¯é‡Œå®é™…ä¸Šæ˜¯ aligned çš„ï¼š
        # loop step k: current_date=k, åšå‡º w_target. è¿™ä¸ª w_target ä¹Ÿå°±æ˜¯ w_k
        # å®ƒçš„æ”¶ç›Šåº”è¯¥æ˜¯ realized_ret[k] (å³ k+1 å¤©çš„æ”¶ç›Š)
        
        # ç®€å•èµ·è§ï¼š
        port_ret = (weights_seq * realized_ret).sum(axis=1)
        
        # æ¢æ‰‹ç‡è®¡ç®—
        # w_diff = |w_t - w_{t-1}|
        # æ³¨æ„ï¼šè¿™é‡Œä¸ºäº†ç®€åŒ–ï¼Œå‡è®¾ w_t ç›´æ¥å˜æˆ w_{t+1}ï¼Œå¿½ç•¥æ—¥å†…ä»·æ ¼å˜åŠ¨å¯¼è‡´çš„æƒé‡æ¼‚ç§»
        w_diff = np.abs(weights_seq[1:] - weights_seq[:-1]).sum(axis=1)
        # è¡¥ä¸Šç¬¬ä¸€å¤©çš„æ¢æ‰‹
        w_diff = np.insert(w_diff, 0, 0.0) 
        
        turnover = w_diff
        cost = turnover * cfg.COST_COEFF
        net_ret = port_ret - cost
        
        wealth = np.cumprod(1 + net_ret)
        results[strat_name]['wealth'] = wealth
        
        # --- ä¿®æ”¹ç‚¹ï¼šå¢åŠ  Sortino å’Œ Calmar æŒ‡æ ‡ ---
        ann_ret = np.mean(net_ret) * 252
        ann_vol = np.std(net_ret) * np.sqrt(252)
        sharpe = (ann_ret - 0.02) / (ann_vol + 1e-6)
        
        # è®¡ç®— Sortino (åªçœ‹ä¸‹è¡Œæ³¢åŠ¨)
        downside_ret = net_ret.copy()
        downside_ret[downside_ret > 0] = 0
        downside_vol = np.std(downside_ret) * np.sqrt(252)
        sortino = (ann_ret - 0.02) / (downside_vol + 1e-6)
        
        # è®¡ç®—å›æ’¤
        cum_max = np.maximum.accumulate(wealth)
        drawdown = (wealth - cum_max) / cum_max
        max_dd = drawdown.min()
        
        # è®¡ç®— Calmar (å¹´åŒ–æ”¶ç›Š / æœ€å¤§å›æ’¤)
        calmar = ann_ret / (abs(max_dd) + 1e-6)
        
        avg_turnover = np.mean(turnover)
        
        metrics.append({
            'Strategy': strat_name,
            'Ann Return': f"{ann_ret:.2%}",
            'Sharpe': f"{sharpe:.2f}",
            'Sortino': f"{sortino:.2f}",  # æ–°å¢
            'Max DD': f"{max_dd:.2%}",
            'Calmar': f"{calmar:.2f}",    # æ–°å¢
            'Turnover': f"{avg_turnover:.2%}",
            '_sort_key': sortino          # æŒ‰ Sortino æ’åº (è¿™æ˜¯æˆ‘ä»¬çš„è®­ç»ƒç›®æ ‡)
        })
        
    metrics_df = pd.DataFrame(metrics).sort_values('_sort_key', ascending=False).drop(columns='_sort_key')
    print("\nğŸ† å›æµ‹ç»“æœæ’è¡Œæ¦œ (Test Set):")
    print(metrics_df)
    metrics_df.to_csv('backtest_metrics.csv', index=False)
    
    # --- ç»˜å›¾ ---
    plt.figure(figsize=(12, 6))
    for strat_name in results:
        wealth = results[strat_name]['wealth']
        plt.plot(plot_dates, wealth, label=strat_name)
        
    plt.title('Cumulative Wealth Comparison')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig('backtest_wealth_curve.png', dpi=300)
    print(f"\nğŸ“ˆ ç»“æœå·²ä¿å­˜ã€‚")

if __name__ == "__main__":
    run_backtest()
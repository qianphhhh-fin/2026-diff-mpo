import torch
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm

from config import cfg
from data_loader import load_and_process_data
from model import MPO_Network

# ==========================
# 1. å®šä¹‰ Sharpe Loss
# ==========================
def sharpe_loss(w_plan, y_future, transaction_cost_coeff=0.0005):
    """
    w_plan: (Batch, Horizon, Assets) ä¼˜åŒ–å™¨äº§å‡ºçš„æƒé‡
    y_future: (Batch, Horizon, Assets) æœªæ¥çš„çœŸå®æ”¶ç›Šç‡
    """
    # 1. è®¡ç®—ç»„åˆæ”¶ç›Š R_p = w * r
    # (Batch, H, N) * (Batch, H, N) -> sum -> (Batch, H)
    portfolio_ret = (w_plan * y_future).sum(dim=2)
    
    # 2. è®¡ç®—äº¤æ˜“æˆæœ¬ (ç®€åŒ–ç‰ˆ: æ—¢ç„¶æ˜¯ Lossï¼Œæˆ‘ä»¬å¸Œæœ›æƒ©ç½šé«˜æ¢æ‰‹)
    # è¿™ä¸€æ­¥åœ¨ Solver é‡Œå·²ç»æƒ©ç½šè¿‡äº†ï¼Œä½†åœ¨ Loss é‡Œå†åŠ ä¸€æ¬¡åŒä¿é™©
    # è¿™é‡Œä¸ºäº†ç®€ä¾¿ï¼Œä¸»è¦çœ‹çº¯æ”¶ç›Šçš„å¤æ™®ï¼ŒæŠŠæˆæœ¬éšå«åœ¨ w çš„é€‰æ‹©ä¸­
    # å¦‚æœ w ä¹±å˜ï¼ŒSolver é‡Œçš„ cost é¡¹ä¼šå¾ˆå¤§ï¼Œå¯¼è‡´ w è¢«çº¦æŸï¼Œ
    # é—´æ¥å¯¼è‡´ portfolio_ret å˜å·® (å› ä¸ºæ²¡é’±èµšäº†)
    
    # 3. è®¡ç®— Sharpe
    # æŒ‰ Batch è®¡ç®—å¹³å‡æ”¶ç›Šå’Œæ ‡å‡†å·®
    # å‡è®¾æ— é£é™©åˆ©ç‡ä¸º 0 (æˆ–è€…å·²ç»æ˜¯è¶…é¢æ”¶ç›Š)
    mean_ret = portfolio_ret.mean(dim=1) # (Batch,)
    std_ret = portfolio_ret.std(dim=1) + 1e-6 # (Batch,)
    
    sharpe = mean_ret / std_ret
    
    # ç›®æ ‡æ˜¯æœ€å¤§åŒ– Sharpe => æœ€å°åŒ– -Sharpe
    return -sharpe.mean()

# ==========================
# 2. è®­ç»ƒä¸»å¾ªç¯
# ==========================
def train():
    # å‡†å¤‡æ•°æ®
    train_loader, test_loader, _ = load_and_process_data()
    
    # åˆå§‹åŒ–æ¨¡å‹
    model = MPO_Network().to(cfg.DEVICE).double() # CVXPY éœ€è¦ Double ç²¾åº¦
    optimizer = optim.Adam(model.parameters(), lr=cfg.LEARNING_RATE)
    
    print(f"ğŸš€ æ¨¡å‹å·²åŠ è½½è‡³ {cfg.DEVICE}. å¼€å§‹è®­ç»ƒ {cfg.EPOCHS} Epochs...")
    
    loss_history = []
    
    for epoch in range(cfg.EPOCHS):
        model.train()
        epoch_loss = 0
        
        # è¿›åº¦æ¡
        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{cfg.EPOCHS}")
        
        for batch_idx, (x, y) in enumerate(pbar):
            x, y = x.to(cfg.DEVICE).double(), y.to(cfg.DEVICE).double()
            
            # åˆå§‹æŒä»“ï¼šå‡è®¾æ¯ä¸ª Batch å¼€å§‹æ—¶æ˜¯ç©ºä»“æˆ–è€…å‡åŒ€æŒä»“
            # åœ¨çœŸå®çš„ LSTM åºåˆ—è®­ç»ƒä¸­ï¼Œåº”è¯¥æŠŠä¸Šä¸€ä¸ª Batch çš„ w ä¼ è¿›æ¥
            # è¿™é‡Œä¸ºäº†ç®€åŒ–ï¼Œå‡è®¾æ¯å¤©æ—©ä¸Šéƒ½ä» 1/N å¼€å§‹è°ƒä»“ (æˆ–è€…å…¨ç°é‡‘)
            # æ›´å¥½çš„åšæ³•æ˜¯: w_prev = torch.ones(...) / N
            w_prev = torch.ones(x.size(0), cfg.NUM_ASSETS, device=cfg.DEVICE, dtype=torch.double) / cfg.NUM_ASSETS
            
            # --- Forward ---
            # w_plan æ˜¯ Solver è§£å‡ºæ¥çš„æœ€ä¼˜è·¯å¾„
            w_plan, mu_pred, L_pred = model(x, w_prev)
            
            # --- Loss ---
            # æˆ‘ä»¬ç”¨çœŸå®çš„æœªæ¥æ”¶ç›Š y æ¥è¯„ä»· w_plan å¥½ä¸å¥½
            loss = sharpe_loss(w_plan, y)
            
            # --- Backward ---
            optimizer.zero_grad()
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª (é˜²æ­¢ LSTM æ¢¯åº¦çˆ†ç‚¸)
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            epoch_loss += loss.item()
            pbar.set_postfix({'SharpeLoss': f"{loss.item():.4f}"})
        
        avg_loss = epoch_loss / len(train_loader)
        loss_history.append(avg_loss)
        print(f"Epoch {epoch+1} Average Loss: {avg_loss:.4f} (Implied Sharpe: {-avg_loss:.4f})")
        
    # ==========================
    # 3. ç®€å•çš„ç»“æœå¯è§†åŒ–
    # ==========================
    plt.figure(figsize=(10, 5))
    plt.plot(loss_history, label='Negative Sharpe Loss')
    plt.title('Training Progress')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)
    plt.savefig('diff_mpo_training_loss.png')
    print("ğŸ“ˆ è®­ç»ƒå®Œæˆï¼ŒLoss æ›²çº¿å·²ä¿å­˜è‡³ training_loss.png")
    
    # ä¿å­˜æ¨¡å‹

    SAVE_PATH = 'models/diff_mpo_sharpe.pth'  # ç§‘å­¦å‘½å
    torch.save(model.state_dict(), SAVE_PATH)
    print(f"ğŸ† Diff-MPO (Ours) æ¨¡å‹å·²ä¿å­˜è‡³: {SAVE_PATH}")


if __name__ == "__main__":
    train()
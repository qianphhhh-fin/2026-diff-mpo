"""
è„šæœ¬åç§°: train_diff_mpo.py
åŠŸèƒ½æè¿°: 
    Diff-MPO æ¨¡å‹çš„ç‹¬ç«‹è®­ç»ƒè„šæœ¬ (Pre-training)ã€‚
    ç”¨äºåœ¨å›æµ‹å¼€å§‹å‰ï¼Œåœ¨æ•´ä¸ªè®­ç»ƒé›†ä¸Šå¯¹æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œæˆ–è€…è¿›è¡Œè¶…å‚æ•°è°ƒè¯•ã€‚

ä¸»è¦åŠŸèƒ½:
    1. calc_composite_loss: å®šä¹‰å¤åˆæŸå¤±å‡½æ•° (Sortino + MaxDD + Turnover)ã€‚
    2. train: ä¸»è®­ç»ƒå¾ªç¯ã€‚
       - åŠ è½½æ•°æ®ã€‚
       - å‰å‘ä¼ æ’­ (Model -> Solver)ã€‚
       - è®¡ç®— Loss (åŒ…å« MSE, MPO Loss, CVaR Penalty)ã€‚
       - åå‘ä¼ æ’­ä¸å‚æ•°æ›´æ–°ã€‚
       - ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡ã€‚

è¾“å…¥:
    - data_loader.py æä¾›çš„æ•°æ®ã€‚
    - config.py çš„é…ç½®ã€‚

è¾“å‡º:
    - è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶ 'models/diff_mpo_sharpe.pth'ã€‚
    - è®­ç»ƒ Loss æ›²çº¿å›¾ 'diff_mpo_training_loss.png'ã€‚

ä¸å…¶ä»–è„šæœ¬çš„å…³ç³»:
    - ç‹¬ç«‹è¿è¡Œçš„å…¥å£è„šæœ¬ã€‚
    - å…¶ calc_composite_loss å‡½æ•°è¢« strategy.py å¤ç”¨ã€‚
"""

import torch
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import os

from config import cfg
from data_loader import load_and_process_data
from model import MPO_Network_Factor

# ==========================
# 1. å®šä¹‰å¤åˆæŸå¤±å‡½æ•° (Composite Loss)
# ==========================
def calc_composite_loss(w_plan, y_future, w_prev, cost_coeff=0.001):
    """
    è®¡ç®—åŒ…å« Sortinoã€MaxDD å’Œ Turnover æƒ©ç½šçš„å¤åˆ Loss
    
    å‚æ•°:
    w_plan: (Batch, Horizon, Assets) -> Solver è¾“å‡ºçš„æœªæ¥ H æ­¥æƒé‡
    y_future: (Batch, Horizon, Assets) -> çœŸå®æœªæ¥æ”¶ç›Šç‡
    w_prev: (Batch, Assets) -> åˆå§‹æŒä»“
    """
    batch_size = w_plan.size(0)
    horizon = w_plan.size(1)
    
    # --- A. æ„å»ºå®Œæ•´çš„èµ„é‡‘æµ ---
    # 1. è®¡ç®—æ¢æ‰‹ç‡ (Turnover)
    # æ‹¼æ¥ w_prev å’Œ w_planï¼Œå½¢æˆå®Œæ•´è·¯å¾„ [w_0, w_1, ..., w_H]
    w_prev_expanded = w_prev.unsqueeze(1) # (B, 1, N)
    w_all = torch.cat([w_prev_expanded, w_plan], dim=1) # (B, H+1, N)
    
    # è®¡ç®—æ¯ä¸€æ­¥çš„æ¢æ‰‹: |w_t - w_{t-1}|
    # dim=2 (Assets) æ±‚å’Œ
    turnover_seq = torch.norm(w_all[:, 1:] - w_all[:, :-1], p=1, dim=2) # (B, H)
    
    # 2. è®¡ç®—å‡€æ”¶ç›Šç‡ (Net Returns)
    # Gross Ret = sum(w * y)
    gross_ret_seq = (w_plan * y_future).sum(dim=2) # (B, H)
    # Net Ret = Gross - Cost
    net_ret_seq = gross_ret_seq - cost_coeff * turnover_seq # (B, H)
    
    # --- B. è®¡ç®—å„ä¸ª Loss ç»„ä»¶ ---
    
    # Component 1: Sortino Ratio (ä»£æ›¿ Sharpe)
    # åªæƒ©ç½šä¸‹è¡Œæ³¢åŠ¨
    mean_ret = net_ret_seq.mean(dim=1)
    # ç­›é€‰å‡ºå°äº 0 çš„æ”¶ç›Šï¼Œè®¡ç®—å…¶å¹³æ–¹å‡å€¼ä½œä¸ºä¸‹è¡Œé£é™©
    downside_returns = torch.clamp(net_ret_seq, max=0.0)
    downside_std = torch.sqrt(torch.mean(downside_returns**2, dim=1) + 1e-8)
    
    # Sortino = Mean / Downside_Dev
    sortino = (mean_ret - 0.0) / (downside_std + 1e-6)
    loss_sortino = -sortino.mean()
    
    # Component 2: Max Drawdown Penalty (æœ€å¤§å›æ’¤æƒ©ç½š)
    # è®¡ç®—ç´¯è®¡å‡€å€¼æ›²çº¿ Wealth Curve
    # log(1+r) è¿‘ä¼¼ rï¼Œç´¯åŠ å¾—åˆ° log wealth
    # cum_log_ret = torch.cumsum(torch.log1p(net_ret_seq), dim=1)
    # æ‰¾åˆ°æˆªæ­¢å½“å‰çš„æœ€é«˜ç‚¹ (Running Max)
    # PyTorch çš„ cummax è¿”å› (values, indices)
    # running_max, _ = torch.cummax(cum_log_ret, dim=1)
    # è®¡ç®—å›æ’¤: Current - Max
    # drawdowns = cum_log_ret - running_max
    # æ‰¾åˆ°æœ€å¤§å›æ’¤ (æœ€å°å€¼)
    # max_dd, _ = torch.min(drawdowns, dim=1) # (B,) æ³¨æ„è¿™æ˜¯è´Ÿæ•°ï¼Œæ¯”å¦‚ -0.1
    
    # æƒ©ç½šé¡¹ï¼šå›æ’¤è¶Šæ·±(è´Ÿå¾—è¶Šå¤š)ï¼ŒLossè¶Šå¤§
    # ä½¿ç”¨å¹³æ–¹æƒ©ç½šï¼Œè®©æ¨¡å‹æåº¦åŒæ¶æ·±å›æ’¤
    # loss_max_dd = torch.mean(max_dd**2) 
    
    # Component 3: Turnover Smoothing (æ¢æ‰‹ç‡å¹³æ»‘)
    # æƒ©ç½šæƒé‡çš„å‰§çƒˆè·³å˜ (L2 Norm of diff)
    # å³ä½¿ Solver å…è®¸æ¢æ‰‹ï¼Œç¥ç»ç½‘ç»œä¹Ÿä¸åº”è¯¥è¾“å‡ºéœ‡è¡çš„ä¿¡å·
    # w_diff_sq = torch.sum((w_all[:, 1:] - w_all[:, :-1])**2, dim=2) # (B, H)
    # loss_smoothing = torch.mean(w_diff_sq)
    
    # --- C. æ€» Loss ---
    # ä» Config è¯»å–ç³»æ•°
    # lambda_dd = getattr(cfg, 'LOSS_GAMMA_DD', 5.0)
    # lambda_turnover = getattr(cfg, 'LOSS_GAMMA_TURNOVER', 1.0)
    
    # [MODIFIED] åªä¿ç•™ Sortinoï¼Œå…¶ä»–æ³¨é‡Šæ‰
    total_loss = loss_sortino # + lambda_dd * loss_max_dd + lambda_turnover * loss_smoothing
    
    return total_loss, {
        "Sortino": -loss_sortino.item(), # è®°å½•æ­£çš„ Sortino æ–¹ä¾¿çœ‹
        # "MaxDD_Penalty": loss_max_dd.item(),
        # "Smooth_Penalty": loss_smoothing.item()
    }

# ==========================
# 2. è®­ç»ƒä¸»å¾ªç¯
# ==========================
# def train():
#     # å‡†å¤‡æ•°æ®
#     train_loader, test_loader, _ = load_and_process_data()
    
#     # åˆå§‹åŒ–æ¨¡å‹
#     model = MPO_Network_Factor().to(cfg.DEVICE).double() 
#     optimizer = optim.Adam(model.parameters(), lr=cfg.LEARNING_RATE)
    
#     print(f"ğŸš€ æ¨¡å‹å·²åŠ è½½è‡³ {cfg.DEVICE}. å¼€å§‹è®­ç»ƒ {cfg.EPOCHS} Epochs...")
#     print(f"   Loss Config: Gamma_DD={getattr(cfg, 'LOSS_GAMMA_DD', 5.0)}, Gamma_Turnover={getattr(cfg, 'LOSS_GAMMA_TURNOVER', 1.0)}")
    
#     loss_history = []
    
#     for epoch in range(cfg.EPOCHS):
#         model.train()
#         epoch_loss = 0
        
#         # è®°å½•ç»†åˆ†æŒ‡æ ‡ç”¨äºç›‘æ§
#         metrics_sum = {"Sortino": 0, "MaxDD_Penalty": 0, "Smooth_Penalty": 0}
        
#         pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{cfg.EPOCHS}")
        
#         for batch_idx, (x, y) in enumerate(pbar):
#             x, y = x.to(cfg.DEVICE).double(), y.to(cfg.DEVICE).double()
            
#             # åˆå§‹æŒä»“ï¼šå‡è®¾æ¯å¤©æ—©ä¸Šéƒ½ä» 1/N å¼€å§‹ (ç®€åŒ–å‡è®¾)
#             # åœ¨æ›´ä¸¥è°¨çš„å®ç°ä¸­ï¼Œå¯ä»¥ç”¨ LSTM state ä¼ é€’çœŸå®çš„ w_prevï¼Œä½†åœ¨ Batch è®­ç»ƒä¸­å¾ˆéš¾åšåˆ°
#             w_prev = torch.ones(x.size(0), cfg.NUM_ASSETS, device=cfg.DEVICE, dtype=torch.double) / cfg.NUM_ASSETS
            
#             # --- Forward ---
#             w_plan, mu_pred, L_pred = model(x, w_prev)
            
#             # --- Composite Loss ---
#             loss_mpo, metrics = calc_composite_loss(w_plan, y, w_prev, cost_coeff=cfg.COST_COEFF)
            
#             # --- Auxiliary Losses ---
#             # 1. MSE Loss for mu prediction
#             # [REMOVED] æ¨¡å‹ä¸å†é¢„æµ‹æœ‰æ„ä¹‰çš„ muï¼ŒMSE Loss å·²æ— æ„ä¹‰
#             # loss_mse = torch.nn.functional.mse_loss(mu_pred, y)
            
#             # 2. Realized Risk Penalty (CVaR Violation)
#             # [REMOVED] æš‚æ—¶åªä¼˜åŒ–çº¯ Sortinoï¼Œç§»é™¤è¾…åŠ©çº¦æŸ
#             # port_ret = (w_plan * y).sum(dim=2)
#             # violation = torch.relu(-port_ret - cfg.CVAR_LIMIT)
#             # loss_realized_risk = torch.mean(violation**2)
            
#             # Total Loss
#             # [MODIFIED] åªåŒ…å« loss_mpo (å³ Sortino)
#             loss = loss_mpo # + 1000.0 * loss_mse + 20.0 * loss_realized_risk
            
#             # --- Backward ---
#             optimizer.zero_grad()
#             loss.backward()
            
#             # æ¢¯åº¦è£å‰ª (å…³é”®ï¼é˜²æ­¢ MaxDD å¯¼è‡´çš„æ¢¯åº¦çˆ†ç‚¸)
#             grad_clip = getattr(cfg, 'GRAD_CLIP', 0.5)
#             torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=grad_clip)
            
#             optimizer.step()
            
#             epoch_loss += loss.item()
            
#             # ç´¯åŠ ç›‘æ§æŒ‡æ ‡
#             for k, v in metrics.items():
#                 metrics_sum[k] += v
                
#             pbar.set_postfix({'Loss': f"{loss.item():.2f}", 'Sortino': f"{metrics['Sortino']:.2f}"})
        
#         avg_loss = epoch_loss / len(train_loader)
#         loss_history.append(avg_loss)
        
#         # æ‰“å°æœ¬ Epoch çš„å¹³å‡æŒ‡æ ‡
#         avg_sortino = metrics_sum["Sortino"] / len(train_loader)
#         avg_dd_pen = metrics_sum["MaxDD_Penalty"] / len(train_loader)
#         print(f"Epoch {epoch+1} | Loss: {avg_loss:.4f} | Avg Sortino: {avg_sortino:.4f} | DD Pen: {avg_dd_pen:.4f}")
        
#     # ==========================
#     # 3. ç»“æœä¿å­˜
#     # ==========================
#     plt.figure(figsize=(10, 5))
#     plt.plot(loss_history, label='Composite Loss')
#     plt.title('Training Progress (Composite Loss)')
#     plt.xlabel('Epoch')
#     plt.ylabel('Loss')
#     plt.legend()
#     plt.grid(True)
#     plt.savefig('diff_mpo_training_loss.png')
#     print("ğŸ“ˆ è®­ç»ƒå®Œæˆï¼ŒLoss æ›²çº¿å·²ä¿å­˜ã€‚")
    
#     SAVE_PATH = 'models/diff_mpo_sharpe.pth' 
#     torch.save(model.state_dict(), SAVE_PATH)
#     print(f"ğŸ† Diff-MPO (Ours) æ¨¡å‹å·²ä¿å­˜è‡³: {SAVE_PATH}")


# if __name__ == "__main__":
#     train()
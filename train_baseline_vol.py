import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from tqdm import tqdm
import os

from config import cfg
from data_loader import load_and_process_data
from model import MPO_Network

os.makedirs('models', exist_ok=True)
MODEL_SAVE_PATH = 'models/baseline_vol_model.pth'

def train_volatility():
    train_loader, _, _ = load_and_process_data()
    
    model = MPO_Network().to(cfg.DEVICE).double()
    optimizer = optim.Adam(model.parameters(), lr=cfg.LEARNING_RATE)
    criterion = nn.MSELoss()
    
    print(f"ğŸŒŠ [Benchmark] å¼€å§‹è®­ç»ƒ Volatility æ¨¡å‹ (for Risk Parity)...")
    print(f"   ç›®æ ‡: è®©é¢„æµ‹çš„ L (åæ–¹å·®å› å­) é€¼è¿‘çœŸå®çš„æ³¢åŠ¨")

    for epoch in range(cfg.EPOCHS):
        model.train()
        epoch_loss = 0
        pbar = tqdm(train_loader, desc=f"Vol Epoch {epoch+1}/{cfg.EPOCHS}")
        
        for x, y in pbar:
            x, y = x.to(cfg.DEVICE).double(), y.to(cfg.DEVICE).double()
            
            # --- æ„é€ æ³¢åŠ¨ç‡æ ‡ç­¾ (Proxy Label) ---
            # çœŸå®æ³¢åŠ¨ç‡å¾ˆéš¾è§‚æµ‹ï¼Œæˆ‘ä»¬ç”¨ y^2 è¿‘ä¼¼ (Ret^2 approx Variance)
            # y: (Batch, Horizon, Assets)
            # target_vol: (Batch, Horizon, Assets) -> è¿™æ˜¯æ–¹å·®
            target_variance = y ** 2
            
            # --- æ‰‹åŠ¨ Forward ---
            _, (h_n, _) = model.lstm(x)
            context = h_n[-1]
            batch_size = x.size(0)
            
            # åªç”¨ L Head (åæ–¹å·®é¢„æµ‹å¤´)
            L_flat = model.L_head(context)
            L_pred = L_flat.view(batch_size, cfg.PREDICT_HORIZON, cfg.NUM_ASSETS, cfg.NUM_ASSETS)
            
            # å¤„ç† L ä¿è¯åˆæ³•æ€§
            mask = torch.tril(torch.ones_like(L_pred))
            L_pred = L_pred * mask
            diag_mask = torch.eye(cfg.NUM_ASSETS, device=cfg.DEVICE).view(1, 1, cfg.NUM_ASSETS, cfg.NUM_ASSETS)
            L_pred = L_pred + diag_mask * (F.softplus(L_pred) + 1e-5 - L_pred)
            
            # è®¡ç®—é¢„æµ‹çš„æ–¹å·® (Predicted Variance)
            # Sigma = L * L.T
            # å¯¹è§’çº¿å…ƒç´  Sigma_ii = sum(L_ik^2)
            # æˆ‘ä»¬åªéœ€è¦å¯¹è§’çº¿éƒ¨åˆ†æ¥åš MSE ç›‘ç£ï¼ˆç®€åŒ–ç‰ˆ Risk Parity åªéœ€è¦æ–¹å·®ï¼‰
            Sigma_diag = torch.diagonal(L_pred @ L_pred.transpose(-1, -2), dim1=-2, dim2=-1)
            
            # Loss: é¢„æµ‹æ–¹å·® vs çœŸå®æ–¹å·®proxy
            loss = criterion(Sigma_diag, target_variance)
            
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            epoch_loss += loss.item()
            pbar.set_postfix({'VolMSE': f"{loss.item():.8f}"})
            
        print(f"Epoch {epoch+1} Avg Vol MSE: {epoch_loss / len(train_loader):.8f}")

    torch.save(model.state_dict(), MODEL_SAVE_PATH)
    print(f"âœ… Volatility åŸºå‡†æ¨¡å‹å·²ä¿å­˜è‡³: {MODEL_SAVE_PATH}")

if __name__ == "__main__":
    train_volatility()
"""
è„šæœ¬åç§°: 0_fetch_data.py
åŠŸèƒ½æè¿°: 
    è´Ÿè´£ä»æœ¬åœ°ç›®å½•å’Œç½‘ç»œæ•°æ®æºè·å–åŸå§‹é‡‘èæ•°æ®ï¼Œå¹¶è¿›è¡Œé¢„å¤„ç†å’Œåˆå¹¶ï¼Œç”Ÿæˆç»Ÿä¸€çš„å®éªŒæ•°æ®é›†ã€‚
    ä¸»è¦ä»»åŠ¡åŒ…æ‹¬ï¼š
    1. è¯»å–æ¸…æ´—åçš„ Fama-French å› å­æ•°æ® (æœ¬åœ° CSV)ã€‚
    2. ä¸‹è½½ FRED å®è§‚ç»æµæ•°æ® (VIX, 10Y Yield, Credit Spread)ã€‚
    3. ä¸‹è½½ SPY å¸‚åœºæ•°æ®å¹¶è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ (æ»šåŠ¨æ”¶ç›Šç‡ã€æ³¢åŠ¨ç‡)ã€‚
    4. åˆå¹¶æ‰€æœ‰æ•°æ®æºï¼Œè¿›è¡Œå¯¹é½å’Œå¡«å……ï¼Œç”Ÿæˆæœ€ç»ˆçš„ CSV æ–‡ä»¶ã€‚

è¾“å…¥:
    - æœ¬åœ°ç›®å½• 'data/raw_data/' ä¸‹çš„ CSV æ–‡ä»¶ (Portfolios_Formed_on_*.csv)ã€‚
    - ç½‘ç»œæ•°æ®æº (FRED API, Yahoo Finance)ã€‚

è¾“å‡º:
    - 'mpo_experiment_data.csv': åˆå¹¶åçš„å®Œæ•´æ•°æ®é›†ï¼Œä¾› config.py å’Œ data_loader.py ä½¿ç”¨ã€‚
    - 'data/macro_features.csv', 'data/market_technicals.csv': ä¸­é—´è¿‡ç¨‹æ–‡ä»¶ã€‚

ä¸å…¶ä»–è„šæœ¬çš„å…³ç³»:
    - å‰ç½®è„šæœ¬: æ—  (è¿™æ˜¯æµæ°´çº¿çš„ç¬¬ä¸€æ­¥)ã€‚
    - åç»§è„šæœ¬: ç”Ÿæˆçš„æ•°æ®è¢« config.py å¼•ç”¨ï¼Œå¹¶ç”± data_loader.py è¯»å–ä»¥æ„å»º PyTorch Datasetã€‚
"""

import pandas as pd
import yfinance as yf
import requests
import io
import numpy as np
import os
import time
from datetime import datetime

# =================é…ç½®åŒºåŸŸ=================
DATA_DIR = 'data'             
RAW_DATA_DIR = os.path.join(DATA_DIR, 'raw_data') # è¯·ç¡®ä¿æ¸…æ´—å¥½çš„csvæ”¾åœ¨è¿™é‡Œ
FINAL_FILE = 'mpo_experiment_data.csv'

START_DATE = '1990-01-01'
END_DATE = datetime.today().strftime('%Y-%m-%d')

# æ ¸å¿ƒèµ„äº§æ± é…ç½®
# æ ¼å¼: { 'å‰ç¼€': ('æ–‡ä»¶å', [åŸå§‹åˆ—å], {åˆ—åæ˜ å°„}) }
FACTOR_CONFIG = {
    # 1. ä»·å€¼å› å­ (Value vs Growth)
    'Val': ('Portfolios_Formed_on_BE-ME_Daily.csv', 
            ['Lo 30', 'Hi 30'], 
            {'Lo 30': 'Growth', 'Hi 30': 'Value'}),
            
    # 2. è§„æ¨¡å› å­ (Size)
    # æ³¨æ„ï¼šæ ¹æ®æ‚¨æä¾›çš„ä¿¡æ¯ï¼Œè¿™ä¸ªæ–‡ä»¶åé‡Œçš„ daily æ˜¯å°å†™
    'Size': ('Portfolios_Formed_on_ME_daily.csv', 
             ['Lo 30', 'Hi 30'], 
             {'Lo 30': 'SmallCap', 'Hi 30': 'LargeCap'}),
             
    # 3. åŠ¨é‡å› å­ (Momentum)
    # ä½¿ç”¨ 12-2 åŠ¨é‡ (æ ‡å‡†å­¦æœ¯å®šä¹‰)
    'Mom': ('10_Portfolios_Prior_12_2_Daily.csv', 
            ['Lo PRIOR', 'Hi PRIOR'], 
            {'Lo PRIOR': 'Loser', 'Hi PRIOR': 'Winner'}),
            
    # 4. ç›ˆåˆ©å› å­ (Profitability)
    'Prof': ('Portfolios_Formed_on_OP_Daily.csv', 
             ['Lo 30', 'Hi 30'], 
             {'Lo 30': 'LowProf', 'Hi 30': 'HighProf'}),

    # 5. æŠ•èµ„å› å­ (Investment)
    'Inv': ('Portfolios_Formed_on_INV_Daily.csv', 
            ['Lo 30', 'Hi 30'], 
            {'Lo 30': 'LowInv', 'Hi 30': 'HighInv'}) 
}
# =========================================

os.makedirs(DATA_DIR, exist_ok=True)

def fetch_french_universe_clean():
    print(f"ğŸ“‚ [æœ¬åœ°] æ­£åœ¨è¯»å–æ¸…æ´—åçš„ CSV æ–‡ä»¶ ({RAW_DATA_DIR})...")
    
    if not os.path.exists(RAW_DATA_DIR):
        print(f"â›” é”™è¯¯ï¼šæ‰¾ä¸åˆ°ç›®å½• {RAW_DATA_DIR}")
        return None

    all_dfs = []
    
    for prefix, (filename, cols_to_keep, rename_map) in FACTOR_CONFIG.items():
        file_path = os.path.join(RAW_DATA_DIR, filename)
        print(f"   ...æ­£åœ¨è¯»å– {prefix} ({filename})")
        
        if not os.path.exists(file_path):
            print(f"      âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            continue
            
        try:
            # 1. ç›´æ¥è¯»å– CSV (å› ä¸ºæ‚¨å·²ç»æ¸…æ´—è¿‡ï¼Œè¡¨å¤´åœ¨ç¬¬ä¸€è¡Œ)
            df = pd.read_csv(file_path)
            
            # 2. æ¸…æ´—åˆ—å (å»é™¤å‰åç©ºæ ¼)
            df.columns = df.columns.str.strip()
            df.dropna(how='all',axis=0,inplace=True)  # åˆ é™¤å…¨ç©ºè¡Œ
            # 3. å¤„ç†æ—¥æœŸåˆ—
            # å‡è®¾ç¬¬ä¸€åˆ—æ˜¯ Date (19260701 è¿™ç§æ ¼å¼)
            if 'Date' in df.columns:
                df['Date'] = df['Date'].astype(int).astype(str).str.strip()
                df['Date'] = pd.to_datetime(df['Date'], format='%Y%m%d', errors='coerce')
                df = df.set_index('Date')
            else:
                print(f"      âš ï¸ è­¦å‘Š: {filename} ä¸­æ²¡æ‰¾åˆ° 'Date' åˆ—ï¼Œå°è¯•ä½¿ç”¨ç¬¬ä¸€åˆ—ä½œä¸ºç´¢å¼•")
                df.iloc[:, 0] = df.iloc[:, 0].astype(str).str.strip()
                df.index = pd.to_datetime(df.iloc[:, 0], format='%Y%m%d', errors='coerce')

            # 4. ç­›é€‰åˆ—
            missing_cols = [c for c in cols_to_keep if c not in df.columns]
            if missing_cols:
                print(f"      âŒ ç¼ºå°‘åˆ—: {missing_cols}ã€‚ç°æœ‰åˆ—: {list(df.columns)[:5]}...")
                continue
                
            df = df[cols_to_keep]
            
            # 5. é‡å‘½å
            new_names = {c: f"{prefix}_{rename_map.get(c, c)}" for c in cols_to_keep}
            df = df.rename(columns=new_names)
            
            # 6. æ•°å€¼æ¸…æ´—
            # French æ•°æ®é€šå¸¸æ˜¯ç™¾åˆ†æ¯” (0.39 -> 0.39%)ï¼Œéœ€è¦é™¤ä»¥ 100
            # ç¼ºå¤±å€¼æ ‡è®°é€šå¸¸æ˜¯ -99.99 æˆ– -999
            df = df.apply(pd.to_numeric, errors='coerce')
            df = df.replace([-99.99, -99.9, -999], np.nan)
            df = df / 100.0
            
            all_dfs.append(df)
            
        except Exception as e:
            print(f"      âŒ è¯»å–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    if not all_dfs:
        print("â›” æœªèƒ½åŠ è½½ä»»ä½•æ•°æ®ã€‚")
        return None

    # åˆå¹¶æ‰€æœ‰å› å­
    print("   æ­£åœ¨åˆå¹¶èµ„äº§...")
    try:
        universe = pd.concat(all_dfs, axis=1, join='outer')
    except Exception as e:
        print(f"â›” åˆå¹¶å¤±è´¥: {e}")
        return None

    # æˆªå–æ—¶é—´
    universe = universe.loc[START_DATE:END_DATE].dropna()
    
    print(f"   âœ… åŸºç¡€èµ„äº§æ± æ„å»ºå®Œæˆã€‚å½¢çŠ¶: {universe.shape}")
    return universe

def fetch_macro_fred():
    # ... (ä¿æŒåŸæœ‰çš„å®è§‚æ•°æ®ä¸‹è½½é€»è¾‘ä¸å˜) ...
    file_path = os.path.join(DATA_DIR, 'macro_features.csv')
    if os.path.exists(file_path):
        print(f"âœ… [æœ¬åœ°] å·²æ£€æµ‹åˆ°å®è§‚æ•°æ® (FRED)ï¼Œè·³è¿‡ä¸‹è½½ã€‚")
        return pd.read_csv(file_path, index_col=0, parse_dates=True)

    print("â¬‡ï¸ [ä¸‹è½½] æ­£åœ¨ä¸‹è½½ FRED å®è§‚æ•°æ®...")
    fred_urls = {
        'VIX': 'https://fred.stlouisfed.org/graph/fredgraph.csv?id=VIXCLS',
        'US10Y': 'https://fred.stlouisfed.org/graph/fredgraph.csv?id=DGS10',
        'Credit_Spread': 'https://fred.stlouisfed.org/graph/fredgraph.csv?id=BAMLH0A0HYM2'
    }
    dfs = []
    try:
        headers = {'User-Agent': 'Mozilla/5.0'} 
        for name, url in fred_urls.items():
            print(f"   ...è·å– {name}")
            r = requests.get(url, headers=headers, timeout=20)
            df = pd.read_csv(io.BytesIO(r.content), index_col=0, parse_dates=True)
            df = df.replace('.', np.nan).astype(float)
            df.columns = [name]
            dfs.append(df)
            time.sleep(1)
        macro_data = pd.concat(dfs, axis=1, sort=True).ffill().loc[START_DATE:END_DATE]
        macro_data.to_csv(file_path)
        return macro_data
    except Exception as e:
        print(f"   âŒ FRED ä¸‹è½½å¤±è´¥: {e}")
        return None

def fetch_yahoo_spy():
    # ... (ä¿æŒåŸæœ‰çš„ SPY ä¸‹è½½é€»è¾‘ä¸å˜) ...
    file_path = os.path.join(DATA_DIR, 'market_technicals.csv')
    if os.path.exists(file_path):
        print(f"âœ… [æœ¬åœ°] å·²æ£€æµ‹åˆ° SPY æ•°æ®ï¼Œè·³è¿‡ã€‚")
        return pd.read_csv(file_path, index_col=0, parse_dates=True)

    print("â¬‡ï¸ [ä¸‹è½½] æ­£åœ¨ä¸‹è½½ SPY (ä½œä¸ºå¸‚åœºç‰¹å¾)...")
    try:
        spy = yf.download('SPY', start=START_DATE, end=END_DATE, progress=False, auto_adjust=True)
        if isinstance(spy.columns, pd.MultiIndex):
            if 'Close' in spy.columns.levels[0]:
                close = spy['Close']
                if spy.columns.nlevels > 1: close = close.iloc[:, 0]
            else: close = spy.iloc[:, 0]
        else: close = spy['Close']
            
        feats = pd.DataFrame(index=spy.index)
        feats['Mkt_Ret_60d'] = close.pct_change(60)
        feats['Mkt_Vol_20d'] = close.pct_change().rolling(20).std()
        feats.dropna(inplace=True)
        feats.to_csv(file_path)
        return feats
    except Exception as e:
        print(f"   âŒ SPY ä¸‹è½½å¤±è´¥: {e}")
        return None

def merge_and_save():
    print("\nğŸ”— å¼€å§‹åˆå¹¶æ•°æ®...")
    df_assets = fetch_french_universe_clean()
    df_macro = fetch_macro_fred()
    df_spy = fetch_yahoo_spy()
    
    if df_assets is None: return

    # åˆå¹¶
    full_df = df_assets.join(df_macro, how='left').join(df_spy, how='left')
    full_df.ffill(inplace=True)
    full_df.dropna(inplace=True)

    full_df.to_csv(FINAL_FILE)
    print(f"\nğŸ‰ æ•°æ®å‡†å¤‡å®Œæˆï¼")
    print(f"   æ–‡ä»¶è·¯å¾„: {FINAL_FILE}")
    print(f"   æ—¶é—´èŒƒå›´: {full_df.index.min().date()} è‡³ {full_df.index.max().date()}")
    print(f"   æ€»è¡Œæ•°: {len(full_df)}")
    
    cols = list(full_df.columns)
    asset_cols = [c for c in cols if '_' in c and any(k in c for k in FACTOR_CONFIG.keys())]
    print(f"   åŒ…å«èµ„äº§ ({len(asset_cols)}ä¸ª): {asset_cols}")

if __name__ == "__main__":
    merge_and_save()
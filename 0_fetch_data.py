import pandas as pd
import yfinance as yf
import requests
import zipfile
import io
import numpy as np
import os
import time
from datetime import datetime

# =================é…ç½®åŒºåŸŸ=================
DATA_DIR = 'data'        # ä¸­é—´æ•°æ®ä¿å­˜ç›®å½•
FINAL_FILE = 'mpo_experiment_data.csv'
START_DATE = '1990-01-01'
END_DATE = datetime.today().strftime('%Y-%m-%d')
# =========================================

# ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
os.makedirs(DATA_DIR, exist_ok=True)

def fetch_fama_french():
    file_path = os.path.join(DATA_DIR, 'fama_french.csv')
    if os.path.exists(file_path):
        print(f"âœ… [æœ¬åœ°] å·²æ£€æµ‹åˆ° Fama-French æ•°æ®ï¼Œè·³è¿‡ä¸‹è½½ã€‚")
        return pd.read_csv(file_path, index_col=0, parse_dates=True)
    
    print("â¬‡ï¸ [ä¸‹è½½] æ­£åœ¨ä¸‹è½½ Fama-French 5å› å­æ•°æ®...")
    url = "https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/F-F_Research_Data_5_Factors_2x3_daily_CSV.zip"
    try:
        response = requests.get(url, timeout=30)
        with zipfile.ZipFile(io.BytesIO(response.content)) as z:
            csv_name = z.namelist()[0]
            with z.open(csv_name) as f:
                df = pd.read_csv(f, skiprows=3, index_col=0)
        
        # æ¸…æ´—
        df.index.name = 'Date'
        df.index = pd.to_datetime(df.index, format='%Y%m%d', errors='coerce')
        df = df.dropna()
        df = df.loc[START_DATE:END_DATE]
        df = df / 100.0 # å•ä½è½¬æ¢
        df.columns = ['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA', 'RF']
        
        # ä¿å­˜ä¸­é—´æ–‡ä»¶
        df.to_csv(file_path)
        print(f"   ğŸ’¾ Fama-French å·²ä¿å­˜è‡³ {file_path}")
        return df
    except Exception as e:
        print(f"   âŒ Fama-French ä¸‹è½½å¤±è´¥: {e}")
        return None

def fetch_macro_fred():
    file_path = os.path.join(DATA_DIR, 'macro_features.csv')
    if os.path.exists(file_path):
        print(f"âœ… [æœ¬åœ°] å·²æ£€æµ‹åˆ°å®è§‚æ•°æ® (FRED)ï¼Œè·³è¿‡ä¸‹è½½ã€‚")
        return pd.read_csv(file_path, index_col=0, parse_dates=True)

    print("â¬‡ï¸ [ä¸‹è½½] æ­£åœ¨ä¸‹è½½ FRED å®è§‚æ•°æ®...")
    fred_urls = {
        'VIX': 'https://fred.stlouisfed.org/graph/fredgraph.csv?id=VIXCLS',
        'US10Y': 'https://fred.stlouisfed.org/graph/fredgraph.csv?id=DGS10',
        'US3M': 'https://fred.stlouisfed.org/graph/fredgraph.csv?id=DTB3',
        'Credit_Spread': 'https://fred.stlouisfed.org/graph/fredgraph.csv?id=BAMLH0A0HYM2'
    }
    
    dfs = []
    try:
        for name, url in fred_urls.items():
            print(f"   ...è·å– {name}")
            # æ·»åŠ  User-Agent é˜²æ­¢è¢«ç®€å•çš„åçˆ¬æ‹¦æˆª
            headers = {'User-Agent': 'Mozilla/5.0'} 
            r = requests.get(url, headers=headers, timeout=20)
            df = pd.read_csv(io.BytesIO(r.content), index_col=0, parse_dates=True)
            df = df.replace('.', np.nan).astype(float)
            df.columns = [name]
            dfs.append(df)
            time.sleep(1) # ç¤¼è²Œæ€§å»¶è¿Ÿï¼Œé˜²æ­¢å°IP
            
        # ä¿®å¤ Pandas è­¦å‘Š: æ˜¾å¼æŒ‡å®š sort=True
        macro_data = pd.concat(dfs, axis=1, sort=True)
        macro_data = macro_data.loc[START_DATE:END_DATE].ffill()
        
        macro_data.to_csv(file_path)
        print(f"   ğŸ’¾ å®è§‚æ•°æ®å·²ä¿å­˜è‡³ {file_path}")
        return macro_data
    except Exception as e:
        print(f"   âŒ FRED ä¸‹è½½å¤±è´¥: {e}")
        return None

def fetch_yahoo_spy():
    file_path = os.path.join(DATA_DIR, 'market_technicals.csv')
    if os.path.exists(file_path):
        print(f"âœ… [æœ¬åœ°] å·²æ£€æµ‹åˆ° SPY æŠ€æœ¯é¢æ•°æ®ï¼Œè·³è¿‡ä¸‹è½½ã€‚")
        return pd.read_csv(file_path, index_col=0, parse_dates=True)

    print("â¬‡ï¸ [ä¸‹è½½] æ­£åœ¨é€šè¿‡ Yahoo Finance ä¸‹è½½ SPY...")
    
    # é‡è¯•æœºåˆ¶ï¼šæœ€å¤šå°è¯• 3 æ¬¡
    max_retries = 3
    for attempt in range(max_retries):
        try:
            # yfinance è‡ªåŠ¨ä¸‹è½½
            spy = yf.download('SPY', start=START_DATE, end=END_DATE, progress=False, auto_adjust=True)
            
            if spy.empty:
                raise ValueError("Yahoo è¿”å›äº†ç©ºæ•°æ®")

            # æ¸…æ´—
            feats = pd.DataFrame(index=spy.index)
            # å¤„ç†å¤šçº§ç´¢å¼•é—®é¢˜ (yfinance æ–°ç‰ˆç‰¹æ€§)
            if isinstance(spy.columns, pd.MultiIndex):
                close = spy['Close']['SPY'] if 'SPY' in spy.columns.levels[1] else spy.iloc[:, 0]
                vol = spy['Volume']['SPY'] if 'SPY' in spy.columns.levels[1] else spy.iloc[:, 1]
            else:
                close = spy['Close']
                vol = spy['Volume']

            feats['Mkt_Ret_20d'] = close.pct_change(20)
            feats['Mkt_Vol_20d'] = close.pct_change().rolling(20).std()
            feats['Mkt_Volume_Log'] = np.log(vol + 1)
            
            feats.to_csv(file_path)
            print(f"   ğŸ’¾ SPY æ•°æ®å·²ä¿å­˜è‡³ {file_path}")
            return feats
            
        except Exception as e:
            print(f"   âš ï¸ å°è¯• {attempt+1}/{max_retries} å¤±è´¥: {e}")
            if "Rate limited" in str(e) or "Too Many Requests" in str(e):
                wait_time = 10 * (attempt + 1)
                print(f"      â³ è§¦å‘é™æµï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)
            else:
                time.sleep(2)
    
    print("   âŒ Yahoo æ•°æ®ä¸‹è½½æœ€ç»ˆå¤±è´¥ã€‚è¯·ç¨åå†è¯•æˆ–æ£€æŸ¥ç½‘ç»œã€‚")
    return None

def merge_and_save():
    print("\nğŸ”— å¼€å§‹åˆå¹¶æ•°æ®...")
    
    df_ff = fetch_fama_french()
    df_macro = fetch_macro_fred()
    df_spy = fetch_yahoo_spy()
    
    # æ£€æŸ¥å®Œæ•´æ€§
    if df_ff is None or df_macro is None or df_spy is None:
        print("\nâ›” é”™è¯¯ï¼šéƒ¨åˆ†æ•°æ®ç¼ºå¤±ï¼Œæ— æ³•åˆå¹¶ã€‚")
        print("   è¯·æŸ¥çœ‹ä¸Šæ–¹æŠ¥é”™ä¿¡æ¯ï¼Œé‡æ–°è¿è¡Œè„šæœ¬ä»¥è¡¥å…¨ç¼ºå¤±éƒ¨åˆ†ã€‚")
        print("   (å·²ä¸‹è½½çš„éƒ¨åˆ†ä¿å­˜åœ¨ /data æ–‡ä»¶å¤¹ä¸­ï¼Œæ— éœ€é‡æ–°ä¸‹è½½)")
        return

    # åˆå¹¶
    print("   æ­£åœ¨å¯¹é½æ—¶é—´æˆ³...")
    full_df = df_ff.join(df_macro, how='left').join(df_spy, how='left')
    
    # å»é™¤ç©ºå€¼ (ä¿ç•™ä¸‰è€…éƒ½æœ‰æ•°æ®çš„æ—¥æœŸ)
    original_len = len(full_df)
    full_df.dropna(inplace=True)
    final_len = len(full_df)
    
    if final_len == 0:
        print("   âš ï¸ è­¦å‘Šï¼šåˆå¹¶åæ•°æ®ä¸ºç©ºï¼è¯·æ£€æŸ¥å„ä¸ªæºçš„æ—¶é—´èŒƒå›´æ˜¯å¦æœ‰é‡å ã€‚")
        return

    full_df.to_csv(FINAL_FILE)
    print(f"\nğŸ‰ å¤§åŠŸå‘Šæˆï¼")
    print(f"   åŸå§‹è¡Œæ•°: {original_len}")
    print(f"   æ¸…æ´—åè¡Œæ•°: {final_len}")
    print(f"   æœ€ç»ˆæ–‡ä»¶: {FINAL_FILE}")
    print(f"   ç‰¹å¾åˆ—è¡¨: {list(full_df.columns)}")

if __name__ == "__main__":
    merge_and_save()
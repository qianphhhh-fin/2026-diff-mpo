import torch
import torch.optim as optim
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from tqdm import tqdm
import os
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader

# å¼•å…¥ä½ çš„æ¨¡å—
from config import cfg
from data_loader import MPODataset
from model import MPO_Network
from train_diff_mpo import calc_composite_loss 

# è®¾ç½®é£æ ¼
plt.style.use('seaborn-v0_8')
device = cfg.DEVICE

def run_walk_forward_experiment():
    print("âš”ï¸ [Walk-Forward Experiment] Diff-MPO vs 1/N æ»šåŠ¨å¯¹å†³å¼€å§‹...")
    
    # ==========================
    # 1. å‡†å¤‡å…¨é‡æ•°æ®
    # ==========================
    df_raw = pd.read_csv(cfg.DATA_PATH, index_col=0, parse_dates=True)
    
    # æå–ç‰¹å¾å’Œæ”¶ç›Šç‡
    # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾ df_raw çš„åˆ—é¡ºåºå’Œ data_loader é‡Œçš„ä¸€è‡´
    # ç‰¹å¾ = å…¨éƒ¨åˆ— (15åˆ—)
    all_features = df_raw.values 
    # ç›®æ ‡èµ„äº§ = Config é‡Œçš„ 10 ä¸ªèµ„äº§
    all_returns = df_raw[cfg.ASSETS].values
    dates = df_raw.index
    
    # è®¾ç½®å›æµ‹æ—¶é—´è½´
    # å»ºè®®ï¼šä» 2018 å¹´å¼€å§‹å›æµ‹ï¼Œæ„å‘³ç€ç¬¬ä¸€æ¬¡è®­ç»ƒç”¨çš„æ˜¯ 1990-2017 çš„æ•°æ®
    TEST_START_YEAR = 2018 
    TEST_END_YEAR = dates[-1].year
    
    # åˆå§‹åŒ–è®°å½•å™¨
    results_dmpo = [] # [(date, return)]
    results_ew = []   # [(date, return)]
    
    # åˆå§‹åŒ–æ¨¡å‹ (Warm Start)
    # æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæ¨¡å‹å®ä¾‹ï¼Œæ¯å¹´åœ¨æ­¤åŸºç¡€ä¸Šå¾®è°ƒ (Fine-tune)ï¼Œæ¨¡æ‹ŸåŸºé‡‘ç»ç†çš„æŒç»­å­¦ä¹ 
    model = MPO_Network().to(device).double()
    
    print(f"   æ•°æ®èŒƒå›´: {dates[0].date()} -> {dates[-1].date()}")
    print(f"   å›æµ‹åŒºé—´: {TEST_START_YEAR} -> {TEST_END_YEAR}")
    print(f"   ç‰¹å¾ç»´åº¦: {all_features.shape[1]}, èµ„äº§æ•°: {cfg.NUM_ASSETS}")
    
    # ==========================
    # 2. æ»šåŠ¨å¾ªç¯ (Year by Year)
    # ==========================
    for year in range(TEST_START_YEAR, TEST_END_YEAR + 1):
        print(f"\nğŸ“… æ­£åœ¨å¤„ç†å¹´ä»½: {year} ...")
        
        # --- A. æ—¶é—´åˆ‡åˆ† ---
        # è®­ç»ƒé›†: ç›´åˆ°å»å¹´æœ« (Expanding)
        train_end_dt = pd.Timestamp(f"{year}-01-01")
        # æµ‹è¯•é›†: ä»Šå¹´æ•´å¹´
        test_end_dt = pd.Timestamp(f"{year+1}-01-01")
        
        train_mask = dates < train_end_dt
        test_mask = (dates >= train_end_dt) & (dates < test_end_dt)
        
        if sum(test_mask) < cfg.LOOKBACK_WINDOW:
            print(f"   âš ï¸ æ•°æ®ä¸è¶³ï¼Œè·³è¿‡ {year}")
            continue
            
        # --- B. æ•°æ®é˜²æ³„æ¼å¤„ç† (Scaler) ---
        scaler = StandardScaler()
        # ä¸¥ç¦ï¼šä½¿ç”¨å…¨é‡æ•°æ® fit
        # å¿…é¡»ï¼šåªç”¨æˆªè‡³å»å¹´çš„æ•°æ® fit
        X_train = scaler.fit_transform(all_features[train_mask])
        Y_train = all_returns[train_mask]
        
        X_test = scaler.transform(all_features[test_mask])
        Y_test = all_returns[test_mask] # è¿™é‡Œçš„ Y_test æ˜¯è¿™ä¸€å¹´çš„çœŸå®æ”¶ç›Šç‡
        test_dates_curr = dates[test_mask]
        
        # æ„å»º DataLoader (Train)
        train_ds = MPODataset(X_train, Y_train, cfg.LOOKBACK_WINDOW, cfg.PREDICT_HORIZON)
        train_loader = DataLoader(train_ds, batch_size=cfg.BATCH_SIZE, shuffle=True, drop_last=True)
        
        # --- C. æ¨¡å‹é‡è®­ç»ƒ (Retrain/Fine-tune) ---
        # æ¯å¹´ä»…éœ€å°‘é‡ Epochs é€‚åº”æ–°é£æ ¼ (ä¾‹å¦‚ 5-10 Epochs)
        # å­¦ä¹ ç‡å¯ä»¥ç¨å¾®å°ä¸€ç‚¹ï¼Œé˜²æ­¢ç¾éš¾æ€§é—å¿˜
        optimizer = optim.Adam(model.parameters(), lr=5e-4) 
        model.train()
        
        train_pbar = tqdm(range(10), desc=f"   Training {year}", leave=False)
        for ep in train_pbar:
            ep_loss = 0
            for x_b, y_b in train_loader:
                x_b, y_b = x_b.to(device).double(), y_b.to(device).double()
                
                # å‡è®¾ w_prev æ¯å¤©é‡ç½®ä¸º 1/N (æˆ–è€…ä½ å¯ä»¥ç»´æŠ¤çœŸå®çš„ w_prev)
                w_prev_b = torch.ones(x_b.size(0), cfg.NUM_ASSETS, device=device, dtype=torch.double) / cfg.NUM_ASSETS
                
                w_plan, _, _ = model(x_b, w_prev_b)
                
                # ä½¿ç”¨ä½ ä¹‹å‰æ”¹å¥½çš„ Composite Loss
                loss, _ = calc_composite_loss(w_plan, y_b, w_prev_b, cost_coeff=cfg.COST_COEFF)
                
                optimizer.zero_grad()
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                optimizer.step()
                ep_loss += loss.item()
            train_pbar.set_postfix({'loss': f"{ep_loss/len(train_loader):.4f}"})
            
        # --- D. æ ·æœ¬å¤–é¢„æµ‹ (Out-of-Sample Inference) ---
        model.eval()
        
        # è¿™é‡Œçš„ Inference éœ€è¦é€æ—¥è¿›è¡Œ (Rolling Inference)
        # ä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬æ„å»ºä¸€ä¸ª Test Datasetï¼Œå®ƒæœ¬è´¨ä¸Šå°±æ˜¯æ»‘åŠ¨çª—å£
        # æ³¨æ„ï¼šMPODataset ä¼šåƒæ‰å‰ Lookback å¤©ï¼Œæ‰€ä»¥æˆ‘ä»¬è¦è¡¥ä¸Šä¸€ç‚¹æ•°æ®
        # è®©æˆ‘ä»¬å– X_test åŠ ä¸Šå‰ Lookback-1 å¤©çš„æ•°æ®ï¼Œä¿è¯é¢„æµ‹ä» 1æœˆ1æ—¥ å¼€å§‹
        
        # æ‰¾åˆ°æµ‹è¯•é›†åœ¨åŸå§‹æ•°æ®ä¸­çš„èµ·å§‹ç´¢å¼•
        test_start_idx = np.where(test_mask)[0][0]
        # å›æº¯ Lookback-1 å¤©
        infer_start_idx = max(0, test_start_idx - cfg.LOOKBACK_WINDOW + 1)
        
        # å‡†å¤‡ Inference æ•°æ®
        X_infer_raw = all_features[infer_start_idx : test_start_idx + len(test_dates_curr)]
        X_infer_scaled = scaler.transform(X_infer_raw) # ç”¨æ—§çš„ scaler è½¬æ¢
        
        # çœŸå®æ”¶ç›Šç‡ (ç”¨äºè®¡ç®—æ¯å¤©çš„ PnL)
        Y_realized = Y_test 
        
        # ç»´æŠ¤ä¸€ä¸ªæ»šåŠ¨çš„ current_w (åˆå§‹ä¸º 1/N)
        curr_w = torch.ones(1, cfg.NUM_ASSETS, device=device, dtype=torch.double) / cfg.NUM_ASSETS
        
        with torch.no_grad():
            for t in range(len(Y_realized)):
                # æ„é€ è¾“å…¥: [t : t+Lookback]
                x_window = X_infer_scaled[t : t + cfg.LOOKBACK_WINDOW]
                
                # å®‰å…¨æ£€æŸ¥
                if len(x_window) != cfg.LOOKBACK_WINDOW: break
                
                x_tensor = torch.tensor(x_window).unsqueeze(0).to(device).double()
                
                # é¢„æµ‹
                w_pred, _, _ = model(x_tensor, curr_w)
                w_action = w_pred[0, 0, :] # å–ç¬¬ä¸€æ­¥åŠ¨ä½œ (H=0)
                
                # --- è®°å½•ç»“æœ ---
                w_np = w_action.cpu().numpy()
                y_today = Y_realized[t]
                
                # DMPO æ”¶ç›Š
                # æ‰£è´¹ï¼šTurnover * Cost
                # å‡è®¾ curr_w æ˜¯æ˜¨å¤©çš„ä»“ä½
                w_prev_np = curr_w[0].cpu().numpy()
                turnover = np.sum(np.abs(w_np - w_prev_np))
                cost = turnover * cfg.COST_COEFF
                
                # è€ƒè™‘ç°é‡‘ä»“ä½: sum(w) <= 1, å‰©ä½™æ˜¯ç°é‡‘(æ”¶ç›Š0)
                # port_ret = w * y + (1-sum(w))*0
                gross_ret = np.sum(w_np * y_today)
                net_ret = gross_ret - cost
                
                results_dmpo.append(net_ret)
                
                # 1/N æ”¶ç›Š (Benchmark)
                w_ew = np.ones(cfg.NUM_ASSETS) / cfg.NUM_ASSETS
                ret_ew = np.sum(w_ew * y_today) # 1/N ä¸æ‰£è´¹æˆ–æ‰£æå°‘ï¼Œè¿™é‡Œç®€åŒ–ä¸æ‰£
                results_ew.append(ret_ew)
                
                # æ›´æ–°çŠ¶æ€
                curr_w = w_action.unsqueeze(0)
                
    # ==========================
    # 3. ç»“æœæ±‡æ€»ä¸è¯„ä¼°
    # ==========================
    print("\nğŸ“Š è®¡ç®—æœ€ç»ˆæŒ‡æ ‡...")
    
    # è½¬æ¢ä¸º Series
    # åªæœ‰è¢«é¢„æµ‹çš„æ—¥å­æ‰æœ‰ç»“æœ
    total_days = len(results_dmpo)
    # å¯¹åº”çš„æ—¥æœŸæ˜¯æ‰€æœ‰æµ‹è¯•å¹´ä»½çš„å¹¶é›†
    # è¿™é‡Œç®€å•å¤„ç†ï¼Œç›´æ¥å–æœ€åçš„ total_days ä¸ªæ—¥æœŸï¼ˆå¯èƒ½ä¼šæœ‰æå…¶å¾®å°çš„å¯¹é½è¯¯å·®ï¼Œä½†åšå®éªŒè¶³å¤Ÿäº†ï¼‰
    # æ›´ä¸¥è°¨çš„åšæ³•æ˜¯åœ¨ loop é‡Œå­˜ date
    idx = dates[-total_days:]
    
    s_dmpo = pd.Series(results_dmpo, index=idx)
    s_ew = pd.Series(results_ew, index=idx)
    
    # å‡€å€¼æ›²çº¿
    wealth_dmpo = (1 + s_dmpo).cumprod()
    wealth_ew = (1 + s_ew).cumprod()
    
    # è®¡ç®—æŒ‡æ ‡å‡½æ•°
    def calc_metrics(series, name):
        ann_ret = series.mean() * 252
        ann_vol = series.std() * np.sqrt(252)
        sharpe = (ann_ret - 0.02) / (ann_vol + 1e-6)
        
        downside = series[series<0]
        sortino = (ann_ret - 0.02) / (downside.std() * np.sqrt(252) + 1e-6)
        
        cum = (1+series).cumprod()
        dd = (cum - cum.cummax()) / cum.cummax()
        max_dd = dd.min()
        
        calmar = ann_ret / (abs(max_dd) + 1e-6)
        
        return {
            "Strategy": name,
            "Return": f"{ann_ret:.2%}",
            "Sharpe": f"{sharpe:.2f}",
            "Sortino": f"{sortino:.2f}",
            "Calmar": f"{calmar:.2f}",
            "MaxDD": f"{max_dd:.2%}"
        }
    
    m1 = calc_metrics(s_dmpo, "Diff-MPO (Walk-Forward)")
    m2 = calc_metrics(s_ew, "1/N Benchmark")
    
    res_df = pd.DataFrame([m1, m2])
    print("\nğŸ† æ»šåŠ¨å›æµ‹æœ€ç»ˆç»“æœ:")
    print(res_df)
    
    # ç”»å›¾
    plt.figure(figsize=(12, 6))
    plt.plot(wealth_dmpo, label='Diff-MPO (Walk-Forward)', linewidth=2)
    plt.plot(wealth_ew, label='1/N Benchmark', linestyle='--', alpha=0.7)
    plt.title(f'Walk-Forward Validation ({TEST_START_YEAR}-{TEST_END_YEAR})\nDiff-MPO Retrained Annually', fontsize=14)
    plt.ylabel('Cumulative Wealth')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # ä¿å­˜
    save_path = 'walk_forward_result.png'
    plt.savefig(save_path, dpi=300)
    print(f"\nğŸ“ˆ å›¾ç‰‡å·²ä¿å­˜è‡³: {save_path}")

if __name__ == "__main__":
    run_walk_forward_experiment()